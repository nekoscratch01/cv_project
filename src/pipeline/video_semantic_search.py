"""Phase 1 entry point: question-driven person retrieval (v2.1).

Pipeline:
- build_index: perception -> features -> evidence map.
- question_search: router -> recall -> hard rules -> VLM verifier (MATCH line).
- Outputs both result video (matched tracks) and all-tracks debug video.
"""

from __future__ import annotations

import json
import asyncio
import inspect
from pathlib import Path
import cv2

from core.config import SystemConfig
from core.perception import VideoPerception
from core.features import TrackFeatureExtractor
from core.evidence import build_evidence_packages
from pipeline.recall import RecallEngine
from core.hard_rules import HardRuleEngine
from core.vlm_types import QueryResult
from typing import Any

VERSION = "v2.1"


class VideoSemanticSystem:
    """
    è§†é¢‘è¯­ä¹‰æ£€ç´¢ç³»ç»Ÿï¼šé—®é¢˜é©±åŠ¨çš„äººç‰©æ£€ç´¢ä¸»å…¥å£ã€‚
    
    è¿™æ˜¯æ•´ä¸ªç³»ç»Ÿçš„"æ€»æŒ‡æŒ¥å®˜"ï¼Œè´Ÿè´£åè°ƒæ‰€æœ‰æ¨¡å—ï¼Œå¯¹å¤–æä¾›ä¸¤ä¸ªæ ¸å¿ƒAPIï¼š
    1. build_index()ï¼šå»ºç«‹è§†é¢‘ç´¢å¼•ï¼ˆç¦»çº¿é˜¶æ®µï¼Œåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰
    2. question_search()ï¼šé—®é¢˜é©±åŠ¨æ£€ç´¢ï¼ˆåœ¨çº¿é˜¶æ®µï¼Œå¯ä»¥å¤šæ¬¡æŸ¥è¯¢ï¼‰
    
    ç³»ç»Ÿæ¶æ„ï¼ˆä¸¤é˜¶æ®µï¼‰ï¼š
    
    ã€é˜¶æ®µä¸€ï¼šå»ºç«‹ç´¢å¼•ã€‘build_index()
        è§†é¢‘æ–‡ä»¶
          â†“
        1. Perceptionï¼ˆæ„ŸçŸ¥å±‚ï¼‰ï¼šYOLO + ByteTrack â†’ æ¯ä¸ªäººçš„è½¨è¿¹è®°å½•
          â†“
        2. Featuresï¼ˆç‰¹å¾å±‚ï¼‰ï¼šè®¡ç®—è¿åŠ¨ç‰¹å¾ â†’ é€Ÿåº¦ã€æ—¶é•¿ç­‰ç»Ÿè®¡æ•°æ®
          â†“
        3. Evidenceï¼ˆè¯æ®å±‚ï¼‰ï¼šæ‰“åŒ…æ‰€æœ‰ä¿¡æ¯ â†’ æ¯ä¸ªäººçš„å®Œæ•´æ¡£æ¡ˆ
          â†“
        å­˜å‚¨åˆ° semantic_database.json
    
    ã€é˜¶æ®µäºŒï¼šé—®é¢˜æ£€ç´¢ã€‘question_search(question)
        ç”¨æˆ·é—®é¢˜ï¼š"æ‰¾ç©¿ç´«è‰²è¡£æœçš„äºº"
          â†“
        1. Recallï¼ˆå¬å›å±‚ï¼‰ï¼šå¿«é€Ÿç­›é€‰ â†’ é€‰å‡ºå€™é€‰äººï¼ˆPhase 1è¿”å›æ‰€æœ‰äººï¼‰
          â†“
        2. VLMï¼ˆç²¾æ’å±‚ï¼‰ï¼šAIåˆ¤æ–­ â†’ å“ªäº›äººåŒ¹é…ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
          â†“
        3. Visualizationï¼ˆå¯è§†åŒ–ï¼‰ï¼šç”»çº¢æ¡† â†’ å¯¼å‡ºé«˜äº®è§†é¢‘
          â†“
        è¿”å›åŒ¹é…ç»“æœ + æ—¶é—´åŒºé—´ + ç†ç”± + è§†é¢‘
    
    è®¾è®¡åŸåˆ™ï¼š
        - ç´¢å¼•é˜¶æ®µå’ŒæŸ¥è¯¢é˜¶æ®µå®Œå…¨åˆ†ç¦»ï¼ˆç´¢å¼•ä¸€æ¬¡ï¼ŒæŸ¥è¯¢å¤šæ¬¡ï¼‰
        - æ‰€æœ‰ä¸­é—´ç»“æœéƒ½ä¿å­˜åœ¨å†…å­˜å’Œç£ç›˜ï¼ˆå¯è°ƒè¯•ã€å¯æ¢å¤ï¼‰
        - æ¨¡å—ä¹‹é—´é€šè¿‡ EvidencePackage äº¤æ¢æ•°æ®ï¼ˆç»Ÿä¸€æ¥å£ï¼‰
        - æ”¯æŒä¾èµ–æ³¨å…¥ï¼ˆrecall_engine å’Œ vlm_client å¯ä»¥æ›¿æ¢ï¼‰
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # åˆ›å»ºç³»ç»Ÿ
        system = VideoSemanticSystem()
        
        # å»ºç«‹ç´¢å¼•ï¼ˆåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰
        system.build_index()
        
        # å¤šæ¬¡æŸ¥è¯¢
        system.question_search("æ‰¾ç©¿ç´«è‰²è¡£æœçš„äºº")
        system.question_search("æ‰¾æˆ´å¸½å­çš„äºº")
        system.question_search("æ‰¾èƒŒåŒ…çš„äºº")
    """

    def __init__(
        self,
        config: SystemConfig | None = None,
        recall_engine: RecallEngine | None = None,
        vlm_client: object | None = None,
        router: Any | None = None,
        hard_rule_engine: HardRuleEngine | None = None,
    ) -> None:
        """
        åˆå§‹åŒ–è§†é¢‘è¯­ä¹‰æ£€ç´¢ç³»ç»Ÿã€‚
        
        Args:
            config: ç³»ç»Ÿé…ç½®å¯¹è±¡ã€‚å¦‚æœä¸º Noneï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                   åŒ…å«è§†é¢‘è·¯å¾„ã€æ¨¡å‹åç§°ã€è¾“å‡ºç›®å½•ç­‰æ‰€æœ‰é…ç½®é¡¹
            recall_engine: å¬å›å¼•æ“ã€‚å¦‚æœä¸º Noneï¼Œä½¿ç”¨é»˜è®¤çš„ RecallEngine
                          æ”¯æŒä¾èµ–æ³¨å…¥ï¼Œæ–¹ä¾¿æµ‹è¯•å’Œæ›¿æ¢å¬å›ç­–ç•¥
            vlm_client: VLMå®¢æˆ·ç«¯ã€‚å¦‚æœä¸º Noneï¼Œä½¿ç”¨é»˜è®¤çš„ GGUF VLM å®¢æˆ·ç«¯
                       æ”¯æŒä¾èµ–æ³¨å…¥ï¼Œæ–¹ä¾¿æµ‹è¯•å’Œä½¿ç”¨ä¸åŒçš„VLMå®ç°
        
        Note:
            - åˆå§‹åŒ–æ—¶åªåˆ›å»ºå¯¹è±¡ï¼Œä¸åŠ è½½è§†é¢‘æˆ–æ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
            - ä¸­é—´ç»“æœï¼ˆtrack_records, featuresç­‰ï¼‰åˆå§‹åŒ–ä¸º None
            - è°ƒç”¨ build_index() åï¼Œè¿™äº›ä¸­é—´ç»“æœæ‰ä¼šè¢«å¡«å……
        """
        self.config = config or SystemConfig()
        self.perception = VideoPerception(self.config)
        # ä¸­é—´ç»“æœï¼Œåˆå§‹åŒ–ä¸º Noneï¼Œè°ƒç”¨ build_index() åå¡«å……
        self.track_records = None  # æ„ŸçŸ¥å±‚è¾“å‡ºï¼šè½¨è¿¹è®°å½•
        self.metadata = None       # æ„ŸçŸ¥å±‚è¾“å‡ºï¼šè§†é¢‘å…ƒæ•°æ®
        self.features = None       # ç‰¹å¾å±‚è¾“å‡ºï¼šè¿åŠ¨ç‰¹å¾
        self.evidence_map = None   # è¯æ®å±‚è¾“å‡ºï¼šè¯æ®åŒ…å­—å…¸
        # å¬å›å¼•æ“å’ŒVLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒä¾èµ–æ³¨å…¥ï¼‰
        self.recall_engine = recall_engine or RecallEngine(config=self.config)
        self.vlm_client = vlm_client or self._build_vlm_client()
        self.router = router or self._build_router()
        self.hard_rule_engine = hard_rule_engine

    def build_index(self) -> None:
        """
        å»ºç«‹è§†é¢‘ç´¢å¼•ï¼šç¦»çº¿å¤„ç†è§†é¢‘ï¼Œç”Ÿæˆæ‰€æœ‰äººçš„è¯æ®åŒ…ã€‚
        
        è¿™æ˜¯ç³»ç»Ÿçš„"ç´¢å¼•é˜¶æ®µ"ï¼Œè´Ÿè´£æŠŠåŸå§‹è§†é¢‘å¤„ç†æˆç»“æ„åŒ–æ•°æ®ã€‚
        åªéœ€è¦è¿è¡Œä¸€æ¬¡ï¼Œå¤„ç†å®Œåå¯ä»¥å¤šæ¬¡æŸ¥è¯¢ã€‚
        
        å·¥ä½œæµç¨‹ï¼ˆ3ä¸ªé˜¶æ®µï¼‰ï¼š
        
        Stage 1: Perceptionï¼ˆæ„ŸçŸ¥ï¼‰
            - è¾“å…¥ï¼šè§†é¢‘æ–‡ä»¶
            - å¤„ç†ï¼šYOLOæ£€æµ‹ + ByteTrackè·Ÿè¸ª
            - è¾“å‡ºï¼štrack_recordsï¼ˆæ¯ä¸ªäººçš„å¸§å·ã€æ¡†ã€è£å‰ªå›¾ï¼‰
                   metadataï¼ˆè§†é¢‘çš„fpsã€åˆ†è¾¨ç‡ç­‰ï¼‰
            - è€—æ—¶ï¼šä¸»è¦ç“¶é¢ˆï¼ˆéœ€è¦é€å¸§å¤„ç†è§†é¢‘ï¼‰
        
        Stage 2: Feature Extractionï¼ˆç‰¹å¾æå–ï¼‰
            - è¾“å…¥ï¼štrack_records + metadata
            - å¤„ç†ï¼šè®¡ç®—è¿åŠ¨ç‰¹å¾ï¼ˆé€Ÿåº¦ã€è·¯å¾„é•¿åº¦ã€æŒç»­æ—¶é—´ï¼‰
            - è¾“å‡ºï¼šfeaturesï¼ˆæ¯ä¸ªäººçš„è¿åŠ¨ç»Ÿè®¡æ•°æ®ï¼‰
            - è€—æ—¶ï¼šå¾ˆå¿«ï¼ˆåªæ˜¯æ•°å€¼è®¡ç®—ï¼‰
        
        Stage 3: Evidence Buildingï¼ˆè¯æ®åŒ…æ„å»ºï¼‰
            - è¾“å…¥ï¼štrack_records + metadata + features
            - å¤„ç†ï¼šæŠŠåˆ†æ•£çš„æ•°æ®æ‰“åŒ…æˆç»Ÿä¸€æ ¼å¼
            - è¾“å‡ºï¼ševidence_mapï¼ˆæ¯ä¸ªäººçš„å®Œæ•´æ¡£æ¡ˆï¼‰
            - è€—æ—¶ï¼šå¾ˆå¿«ï¼ˆåªæ˜¯æ•°æ®é‡ç»„ï¼‰
        
        æœ€åï¼šæŒä¹…åŒ–åˆ°ç£ç›˜
            - ä¿å­˜ semantic_database.jsonï¼ˆåŒ…å«æ‰€æœ‰è½¨è¿¹å’Œç‰¹å¾ï¼‰
            - æ–¹ä¾¿è°ƒè¯•ã€æ¢å¤ã€åˆ†æ
        
        Returns:
            Noneï¼ˆç»“æœä¿å­˜åœ¨ self.track_records, self.features, self.evidence_mapï¼‰
        
        Raises:
            å¯èƒ½çš„å¼‚å¸¸ï¼š
            - è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸå
            - YOLOæ¨¡å‹åŠ è½½å¤±è´¥
            - ç£ç›˜ç©ºé—´ä¸è¶³ï¼ˆè£å‰ªå›¾å’Œæ•°æ®åº“æ–‡ä»¶ï¼‰
        
        Note:
            - è¿™ä¸ªæ–¹æ³•ä¼šä¿®æ”¹ self çš„å¤šä¸ªå±æ€§ï¼ˆtrack_recordsç­‰ï¼‰
            - å¤„ç†æ—¶é—´å–å†³äºè§†é¢‘é•¿åº¦å’Œåˆ†è¾¨ç‡ï¼ˆä¾‹å¦‚5åˆ†é’Ÿè§†é¢‘çº¦éœ€5-10åˆ†é’Ÿï¼‰
            - è¾“å‡ºç›®å½•ä¼šè‡ªåŠ¨åˆ›å»ºï¼ˆconfig.output_dirï¼‰
            - å¯ä»¥å¤šæ¬¡è°ƒç”¨ï¼Œä¼šè¦†ç›–ä¹‹å‰çš„ç»“æœ
        
        ä½¿ç”¨ç¤ºä¾‹ï¼š
            system = VideoSemanticSystem()
            system.build_index()  # å¤„ç†è§†é¢‘ï¼Œç”Ÿæˆç´¢å¼•
            # ä¹‹åå¯ä»¥å¤šæ¬¡æŸ¥è¯¢ï¼Œä¸éœ€è¦é‡æ–°ç´¢å¼•
        """
        print("\n=== Stage 1: Perception ===")
        # æ„ŸçŸ¥å±‚ï¼šæ£€æµ‹å’Œè·Ÿè¸ª
        self.track_records, self.metadata = self.perception.process()
        print(f"   âœ… Valid tracks: {len(self.track_records)}")

        print("\n=== Stage 2: Feature Extraction ===")
        # ç‰¹å¾å±‚ï¼šè®¡ç®—è¿åŠ¨ç‰¹å¾
        feature_extractor = TrackFeatureExtractor(self.metadata)
        self.features = feature_extractor.extract(self.track_records)
        print("   âœ… Track features computed")

        print("\n=== Stage 3: Build evidence packages ===")
        # è¯æ®å±‚ï¼šæ‰“åŒ…æ‰€æœ‰ä¿¡æ¯
        video_id = Path(self.config.video_path).stem  # æå–æ–‡ä»¶åä½œä¸ºvideo_id
        self.evidence_map = build_evidence_packages(
            video_id,
            self.track_records,
            self.metadata,
            self.features,
            video_path=str(self.config.video_path),
        )
        print(f"   âœ… Built {len(self.evidence_map)} evidence packages")

        # æŒä¹…åŒ–ï¼šä¿å­˜åˆ°ç£ç›˜
        self._persist_database()

    def question_search(self, question: str, *, top_k: int = 5, recall_limit: int | None = None):
        """
        é—®é¢˜é©±åŠ¨æ£€ç´¢ï¼šç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œæ‰¾å‡ºåŒ¹é…çš„äººã€‚
        
        è¿™æ˜¯ç³»ç»Ÿçš„"æŸ¥è¯¢é˜¶æ®µ"ï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·é—®é¢˜æ‰¾å‡ºåŒ¹é…çš„è½¨è¿¹ã€‚
        å¯ä»¥å¤šæ¬¡è°ƒç”¨ï¼Œä¸éœ€è¦é‡æ–°å»ºç«‹ç´¢å¼•ã€‚
        
        å·¥ä½œæµç¨‹ï¼ˆ4ä¸ªæ­¥éª¤ï¼‰ï¼š
        
        Step 1: å¬å›ï¼ˆRecallï¼‰
            - è¾“å…¥ï¼šé—®é¢˜ + æ‰€æœ‰è¯æ®åŒ…
            - å¤„ç†ï¼šå¿«é€Ÿç­›é€‰å€™é€‰äººï¼ˆPhase 1è¿”å›æ‰€æœ‰äººï¼‰
            - è¾“å‡ºï¼šå€™é€‰è¯æ®åŒ…åˆ—è¡¨
            - ç›®çš„ï¼šå‡å°‘VLMçš„å·¥ä½œé‡ï¼ˆæœªæ¥ç‰ˆæœ¬ä¼šåšçœŸæ­£çš„è¿‡æ»¤ï¼‰
        
        Step 2: VLMç²¾æ’ï¼ˆVLM Rankingï¼‰
            - è¾“å…¥ï¼šé—®é¢˜ + å€™é€‰è¯æ®åŒ…
            - å¤„ç†ï¼šVLMé€ä¸ªåˆ¤æ–­æ˜¯å¦åŒ¹é…
            - è¾“å‡ºï¼šåŒ¹é…çš„è½¨è¿¹ + åˆ†æ•° + ç†ç”±
            - ç›®çš„ï¼šå‡†ç¡®åˆ¤æ–­å“ªäº›äººç¬¦åˆæè¿°
        
        Step 4: å¯è§†åŒ–ï¼ˆVisualizationï¼‰
            - è¾“å…¥ï¼šåŒ¹é…çš„track_idåˆ—è¡¨
            - å¤„ç†ï¼šåœ¨åŸè§†é¢‘ä¸Šç”»çº¢æ¡†
            - è¾“å‡ºï¼šé«˜äº®è§†é¢‘æ–‡ä»¶ï¼ˆtracking_xxx.mp4ï¼‰
            - ç›®çš„ï¼šè®©ç”¨æˆ·ç›´è§‚çœ‹åˆ°ç»“æœ
        
        Args:
            question: ç”¨æˆ·çš„æŸ¥è¯¢é—®é¢˜ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
                     ä¾‹å¦‚ï¼š"æ‰¾å‡ºç©¿ç´«è‰²è¡£æœçš„äºº"
                          "æ‰¾æˆ´ç‰›ä»”å¸½çš„äºº"
                          "æ‰¾èƒŒåœ†å½¢èƒŒåŒ…çš„äºº"
            recall_limit: å¬å›é˜¶æ®µçš„å€™é€‰æ•°é‡é™åˆ¶ï¼ˆå¯é€‰ï¼‰
                         ä¾‹å¦‚ï¼šrecall_limit=20 è¡¨ç¤ºæœ€å¤šç»™VLMçœ‹20ä¸ªå€™é€‰
                         å¦‚æœä¸º Noneï¼ŒPhase 1ä¼šè¿”å›æ‰€æœ‰è½¨è¿¹
        
        Returns:
            åŒ¹é…ç»“æœåˆ—è¡¨ï¼Œæ ¼å¼ï¼š[QueryResult, QueryResult, ...]ï¼ˆå…¨éƒ¨åŒ¹é…ï¼Œä¸æˆªæ–­ï¼‰
            æ¯ä¸ªç»“æœåŒ…å«ï¼štrack_id, start_s, end_s, score, reason
            å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…ï¼Œè¿”å›ç©ºåˆ—è¡¨ []
        
        Raises:
            RuntimeError: å¦‚æœè¿˜æ²¡è°ƒç”¨ build_index()
        
        Side Effects:
            - åœ¨ config.output_dir ä¸‹ç”Ÿæˆé«˜äº®è§†é¢‘ï¼štracking_<question>.mp4
            - æ‰“å°æŸ¥è¯¢è¿‡ç¨‹å’Œç»“æœåˆ°æ§åˆ¶å°
        
        Note:
            - å¿…é¡»å…ˆè°ƒç”¨ build_index() å»ºç«‹ç´¢å¼•
            - question ä¸­çš„ç©ºæ ¼ä¼šè¢«æ›¿æ¢æˆä¸‹åˆ’çº¿ï¼ˆç”¨äºè§†é¢‘æ–‡ä»¶åï¼‰
            - å¦‚æœæ²¡æœ‰åŒ¹é…ç»“æœï¼Œä¸ä¼šç”Ÿæˆè§†é¢‘æ–‡ä»¶
            - VLMæ¨ç†æ˜¯ä¸»è¦è€—æ—¶ï¼ˆæ¯ä¸ªå€™é€‰çº¦1-3ç§’ï¼‰
        
        ä½¿ç”¨ç¤ºä¾‹ï¼š
            # å…ˆå»ºç«‹ç´¢å¼•
            system = VideoSemanticSystem()
            system.build_index()
            
            # æŸ¥è¯¢1ï¼šæ‰¾ç©¿ç´«è‰²è¡£æœçš„äºº
            results = system.question_search("æ‰¾ç©¿ç´«è‰²è¡£æœçš„äºº", top_k=5)
            for r in results:
                print(f"Track {r.track_id}: {r.reason}")
            
            # æŸ¥è¯¢2ï¼šæ‰¾æˆ´å¸½å­çš„äººï¼ˆä¸éœ€è¦é‡æ–°ç´¢å¼•ï¼‰
            results = system.question_search("æ‰¾æˆ´å¸½å­çš„äºº", top_k=3)
        """
        # æ£€æŸ¥æ˜¯å¦å·²ç»å»ºç«‹ç´¢å¼•
        if self.evidence_map is None:
            raise RuntimeError("Please run build_index() first")

        print(f"\n=== Version: {VERSION} ===")
        print("\n=== Query: Question-driven retrieval ===")
        print(f"Query: {question}")

        plan = self.router.build_plan(question)
        if inspect.isawaitable(plan):
            plan = self._run_coroutine(plan)
        print("   ğŸ§­ Routing plan:", plan.to_dict())

        # Step 1: å¬å›é˜¶æ®µï¼ˆç­›é€‰å€™é€‰ï¼‰
        all_tracks = list(self.evidence_map.values())
        recall_top_k = recall_limit or len(all_tracks)
        plan.constraints["limit"] = len(all_tracks)
        candidates = self.recall_engine.visual_filter(
            all_tracks,
            description=plan.description,
            visual_tags=plan.visual_tags,
            top_k=recall_top_k,
        )
        print(f"   ğŸ” Candidate tracks: {len(candidates)}")

        # Step 1.5: Hard Rule Engine
        hard_engine = self._ensure_hard_rule_engine()
        candidates = hard_engine.apply_constraints(candidates, plan)
        print(f"   ğŸ“ After hard rules: {len(candidates)}")
        if candidates:
            print(f"   ğŸ”¢ Candidate IDs: {', '.join(str(c.track_id) for c in candidates)}")
        if not candidates:
            print("   âŒ No candidates after hard rules")
            return []

        # Step 2: VLMç²¾æ’é˜¶æ®µï¼ˆAIåˆ¤æ–­ï¼‰
        vlm_results = self._run_vlm_verification(question, candidates, plan, top_k=None)
        if not vlm_results:
            print("   âŒ No matching tracks")
            safe_name = question.replace(" ", "_")
            video_output = self.config.output_dir / f"tracking_{safe_name}.mp4"
            debug_output = self.config.output_dir / f"tracking_all_tracks_{safe_name}.mp4"

            # å€™é€‰é«˜äº®ï¼ˆå¦‚æœæœ‰å€™é€‰åˆ™ç”»æ¡†ï¼Œæ²¡æœ‰åˆ™è·³è¿‡ï¼‰
            candidate_ids = [c.track_id for c in candidates]
            if candidate_ids:
                self.perception.render_highlight_video(
                    self.track_records,
                    self.metadata,
                    candidate_ids,
                    video_output,
                    label_text=f"candidates: {question}",
                )
                print(f"   ğŸï¸ Candidate video: {video_output}")
            else:
                self._write_raw_video(video_output)
                print(f"   ğŸï¸ Candidate video (raw, no candidates): {video_output}")

            # å…¨è½¨è¿¹è°ƒè¯•ï¼šæ€»æ˜¯ç”»å‡ºæ‰€æœ‰è½¨è¿¹ï¼Œä¾¿äºæ¯”å¯¹
            all_track_ids = list(self.track_records.keys())
            self.perception.render_highlight_video(
                self.track_records,
                self.metadata,
                all_track_ids,
                debug_output,
                label_text="all tracks",
            )
            print(f"   ğŸï¸ All-tracks video: {debug_output}")
            return []

        # Step 3: ä¿ç•™å…¨éƒ¨åŒ¹é…ï¼ˆä¸æˆªæ–­ï¼‰ï¼Œä»…ç”¨äºå±•ç¤ºæ’åº
        vlm_results.sort(key=lambda r: r.score, reverse=True)
        matches = vlm_results
        print("   âœ… VLM matches (all is_match):")
        for item in matches:
            print(
                f"      - Track {item.track_id}: {item.start_s:.1f}s â†’ {item.end_s:.1f}s | score={item.score:.2f} | reason: {item.reason}"
            )

        # æ±‡æ€»ä¸€å¥è¯å›ç­”
        if matches:
            summary_parts = [
                f"track {m.track_id} ({m.start_s:.1f}sâ€“{m.end_s:.1f}s): {m.reason}"
                for m in matches
            ]
            final_answer = f"Found {len(matches)} matches. " + " | ".join(summary_parts)
        else:
            final_answer = "No matching tracks found."
        print(f"\nğŸ“ Final answer: {final_answer}")

        # Step 4: å¯è§†åŒ–ï¼ˆä»…é«˜äº®åŒ¹é…è½¨è¿¹ï¼‰
        track_ids = [item.track_id for item in matches]
        safe_name = question.replace(" ", "_")  # ç©ºæ ¼æ›¿æ¢æˆä¸‹åˆ’çº¿
        video_output = self.config.output_dir / f"tracking_{safe_name}.mp4"
        self.perception.render_highlight_video(
            self.track_records,
            self.metadata,
            track_ids,
            video_output,
            label_text=question,
        )

        # é¢å¤–è¾“å‡ºï¼šå…¨é‡è½¨è¿¹è°ƒè¯•è§†é¢‘ï¼Œä¾¿äºæ¯”å¯¹
        all_track_ids = list(self.track_records.keys())
        debug_output = self.config.output_dir / f"tracking_all_tracks_{safe_name}.mp4"
        self.perception.render_highlight_video(
            self.track_records,
            self.metadata,
            all_track_ids,
            debug_output,
            label_text="all tracks",
        )
        print(f"   ğŸï¸ Result video: {video_output}")
        print(f"   ğŸï¸ All-tracks video: {debug_output}")

        return matches

    def _run_vlm_verification(self, question: str, candidates, plan, top_k: int | None):
        """
        åœ¨ vLLM é€‚é…å™¨ï¼ˆInferencePortï¼‰ä¸æ—§ç‰ˆ HF å®¢æˆ·ç«¯ä¹‹é—´åšæ¡¥æ¥ã€‚
        """
        if hasattr(self.vlm_client, "verify_batch"):
            plan_context = self._build_plan_context(plan)
            results: list[QueryResult] = []
            batch_size = max(1, min(3, getattr(self.config, "vlm_batch_size", 3)))
            for i in range(0, len(candidates), batch_size):
                chunk = candidates[i : i + batch_size]
                verifications = self._run_coroutine(
                    self.vlm_client.verify_batch(
                        packages=chunk,
                        question=question,
                        plan_context=plan_context,
                        concurrency=batch_size,
                    )
                )
                for package, verdict in zip(chunk, verifications):
                    if not verdict.is_match:
                        continue
                    results.append(
                        QueryResult(
                            track_id=package.track_id,
                            start_s=package.start_time_seconds,
                            end_s=package.end_time_seconds,
                            score=verdict.confidence,
                            reason=verdict.reason,
                        )
                    )
            return results

        # å…¼å®¹æ—§ HF å®¢æˆ·ç«¯æ¥å£
        return self.vlm_client.answer(question, candidates, plan=plan, top_k=top_k)  # type: ignore[no-any-return]

    @staticmethod
    def _build_plan_context(plan) -> str:
        try:
            return json.dumps(plan.to_dict(), ensure_ascii=False)
        except Exception:
            return ""

    def _run_coroutine(self, coro):
        try:
            return asyncio.run(coro)
        except RuntimeError as exc:
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                raise
            if loop.is_running():
                raise RuntimeError(
                    "vLLM verification requires a non-async context; please call the async adapter directly."
                ) from exc
            return loop.run_until_complete(coro)

    def _write_raw_video(self, output_path: Path) -> None:
        """æŠŠåŸè§†é¢‘ç›´æ¥æ‹·è´ä¸º MP4ï¼ˆæ— ä»»ä½•æ ‡æ³¨ï¼‰ï¼Œç”¨äºç©ºç»“æœæ—¶çš„å ä½è¾“å‡ºã€‚"""
        cap = cv2.VideoCapture(str(self.config.video_path))
        if not cap.isOpened():
            print(f"   âš ï¸ Cannot open video for copy: {self.config.video_path}")
            return
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = self.metadata.fps if self.metadata else cap.get(cv2.CAP_PROP_FPS) or 25.0
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
        if not out.isOpened():
            print(f"   âš ï¸ Cannot create raw video file: {output_path}")
            cap.release()
            return
        frames = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            out.write(frame)
            frames += 1
        cap.release()
        out.release()
        if frames == 0:
            print(f"   âš ï¸ Raw video copy has 0 frames: {output_path}")

    def _ensure_hard_rule_engine(self) -> HardRuleEngine:
        if self.hard_rule_engine is None:
            if self.metadata is None:
                raise RuntimeError("Missing metadata; cannot initialize HardRuleEngine")
            self.hard_rule_engine = HardRuleEngine(self.config, self.metadata)
        elif self.hard_rule_engine.metadata is None and self.metadata is not None:
            self.hard_rule_engine.metadata = self.metadata
        return self.hard_rule_engine

    def _build_router(self):
        if self.config.router_backend == "simple":
            from pipeline.router import SimpleRouter
            return SimpleRouter()
        if self.config.router_backend == "vllm":
            from pipeline.router_vlm import VlmRouter

            return VlmRouter(base_url=self.config.vllm_endpoint, model=self.config.vllm_model_name)
        raise RuntimeError(f"Unknown router_backend: {self.config.router_backend!r}")

    def _build_vlm_client(self):
        if self.config.vlm_backend != "vllm":
            raise RuntimeError("vlm_backend must be 'vllm' (no downgrade fallback).")

        from adapters.inference.vllm_adapter import VllmAdapter, VllmConfig

        return VllmAdapter(
            VllmConfig(
                endpoint=self.config.vllm_endpoint,
                model_name=self.config.vllm_model_name,
                temperature=self.config.vlm_temperature,
                max_tokens=self.config.vlm_max_new_tokens,
                max_images_per_request=getattr(self.config, "vlm_batch_size", 5),
            )
        )

    def _persist_database(self) -> None:
        """
        æŒä¹…åŒ–æ•°æ®åº“ï¼šä¿å­˜æ‰€æœ‰è½¨è¿¹å’Œç‰¹å¾åˆ°JSONæ–‡ä»¶ã€‚
        
        è¿™æ˜¯ä¸€ä¸ªå†…éƒ¨æ–¹æ³•ï¼ˆç§æœ‰æ–¹æ³•ï¼‰ï¼Œç”± build_index() è°ƒç”¨ã€‚
        æŠŠå†…å­˜ä¸­çš„æ‰€æœ‰æ•°æ®ä¿å­˜åˆ°ç£ç›˜ï¼Œæ–¹ä¾¿ï¼š
        1. è°ƒè¯•ï¼šæŸ¥çœ‹ä¸­é—´ç»“æœï¼Œå®šä½é—®é¢˜
        2. æ¢å¤ï¼šç¨‹åºå´©æºƒåå¯ä»¥ä»æ–‡ä»¶æ¢å¤
        3. åˆ†æï¼šç”¨å…¶ä»–å·¥å…·åˆ†æè½¨è¿¹æ•°æ®
        
        ä¿å­˜çš„å†…å®¹ï¼š
            - video: è§†é¢‘æ–‡ä»¶è·¯å¾„
            - tracks: æ‰€æœ‰è½¨è¿¹çš„åŸå§‹æ•°æ®ï¼ˆå¸§å·ã€æ¡†ã€è£å‰ªå›¾è·¯å¾„ï¼‰
            - features: æ‰€æœ‰è½¨è¿¹çš„è¿åŠ¨ç‰¹å¾ï¼ˆé€Ÿåº¦ã€æ—¶é•¿ç­‰ï¼‰
        
        æ–‡ä»¶æ ¼å¼ï¼š
            JSONæ ¼å¼ï¼ŒUTF-8ç¼–ç ï¼Œå¸¦ç¼©è¿›ï¼ˆæ–¹ä¾¿äººç±»é˜…è¯»ï¼‰
            æ–‡ä»¶åï¼šsemantic_database.json
            ä½ç½®ï¼šconfig.output_dir / "semantic_database.json"
        
        Note:
            - è¿™æ˜¯ç§æœ‰æ–¹æ³•ï¼Œä¸åº”è¯¥è¢«å¤–éƒ¨ç›´æ¥è°ƒç”¨
            - å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œä¼šè¢«è¦†ç›–
            - ä¿å­˜çš„æ˜¯æ–‡ä»¶è·¯å¾„ï¼ˆcropsï¼‰ï¼Œä¸æ˜¯å›¾ç‰‡æœ¬èº«
            - track_id ä¼šè¢«è½¬æˆå­—ç¬¦ä¸²ï¼ˆJSONçš„keyå¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼‰
        
        æ–‡ä»¶ç»“æ„ç¤ºä¾‹ï¼š
            {
              "video": "/path/to/video.mp4",
              "tracks": {
                "1": {
                  "frames": [1, 2, 3, ...],
                  "bboxes": [[50,100,150,300], ...],
                  "crops": ["crops/id001_frame00001.jpg", ...]
                },
                "2": {...}
              },
              "features": {
                "1": {
                  "avg_speed_px_s": 75.0,
                  "max_speed_px_s": 120.0,
                  "path_length_px": 636.0,
                  "duration_s": 29.97
                },
                "2": {...}
              }
            }
        """
        db_path = self.config.output_dir / "semantic_database.json"
        
        # è½¬æ¢ features ä¸ºå­—å…¸æ ¼å¼ï¼ˆtrack_idå¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼‰
        feature_payload = (
            {str(tid): feature.to_dict() for tid, feature in self.features.items()}
            if self.features
            else {}
        )
        
        # æ„é€ å®Œæ•´çš„æ•°æ®ç»“æ„
        payload = {
            "video": str(self.config.video_path),
            "tracks": {
                str(tid): {
                    "frames": record.frames,
                    "bboxes": record.bboxes,
                    "crops": record.crops,
                }
                for tid, record in self.track_records.items()
            },
            "features": feature_payload,
        }
        
        # å†™å…¥JSONæ–‡ä»¶
        with open(db_path, "w", encoding="utf-8") as f:
            json.dump(
                payload,
                f,
                indent=2,              # ç¼©è¿›2ä¸ªç©ºæ ¼ï¼ˆç¾è§‚ï¼‰
                ensure_ascii=False     # å…è®¸ä¸­æ–‡ç­‰éASCIIå­—ç¬¦
            )
        print(f"   ğŸ’¾ Database saved: {db_path}")


def run_demo() -> None:
    """
    è¿è¡Œæ¼”ç¤ºç¨‹åºï¼šå±•ç¤ºç³»ç»Ÿçš„å®Œæ•´å·¥ä½œæµç¨‹ã€‚
    
    è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºå‡½æ•°ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨ VideoSemanticSystemï¼š
    1. åˆ›å»ºç³»ç»Ÿå®ä¾‹ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    2. å»ºç«‹ç´¢å¼•ï¼ˆå¤„ç†è§†é¢‘ï¼‰
    3. æ‰§è¡ŒæŸ¥è¯¢ï¼ˆé—®é¢˜é©±åŠ¨æ£€ç´¢ï¼‰
    
    æ¼”ç¤ºæŸ¥è¯¢ï¼š
        "æ‰¾å‡ºç©¿ç´«è‰²è¡£æœçš„äºº"
    
    è¾“å‡ºï¼š
        - æ§åˆ¶å°æ‰“å°ï¼šå¤„ç†è¿›åº¦ã€åŒ¹é…ç»“æœ
        - æ–‡ä»¶è¾“å‡ºï¼š
            * crops/ï¼šè£å‰ªå›¾æ–‡ä»¶å¤¹
            * semantic_database.jsonï¼šæ•°æ®åº“æ–‡ä»¶
            * tracking_æ‰¾å‡ºç©¿ç´«è‰²è¡£æœçš„äºº.mp4ï¼šé«˜äº®è§†é¢‘
    
    Note:
        - ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆconfig.py ä¸­çš„é…ç½®ï¼‰
        - å¦‚æœè¦ä¿®æ”¹è§†é¢‘è·¯å¾„æˆ–å…¶ä»–é…ç½®ï¼Œéœ€è¦ä¿®æ”¹ config.py
        - è¿™ä¸ªå‡½æ•°ä¸»è¦ç”¨äºå¿«é€Ÿæµ‹è¯•å’Œæ¼”ç¤º
    
    ä½¿ç”¨æ–¹æ³•ï¼š
        python video_semantic_search.py
    """
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = VideoSemanticSystem()
    
    # å»ºç«‹ç´¢å¼•ï¼ˆå¤„ç†è§†é¢‘ï¼‰
    system.build_index()

    # æ‰§è¡Œæ¼”ç¤ºæŸ¥è¯¢
    print("\n=== Demo Queries ===")
    system.question_search("Find the person in blue moving left â€” are they running or walking?", top_k=5)


if __name__ == "__main__":
    run_demo()
