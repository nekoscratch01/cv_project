"""Phase 1 entry point: question-driven person retrieval."""

from __future__ import annotations

import json
from pathlib import Path

from pipeline import (
    SystemConfig,
    VideoPerception,
    TrackFeatureExtractor,
    build_evidence_packages,
    RecallEngine,
    QwenVLMClient,
)


class VideoSemanticSystem:
    """High-level orchestrator exposing build + query APIs."""

    def __init__(self, config: SystemConfig | None = None) -> None:
        self.config = config or SystemConfig()
        self.perception = VideoPerception(self.config)
        self.track_records = None
        self.metadata = None
        self.features = None
        self.evidence_map = None
        self.recall_engine = RecallEngine()
        self.vlm_client = QwenVLMClient(self.config)

    def build_index(self) -> None:
        print("\n=== Stage 1: Perception ===")
        self.track_records, self.metadata = self.perception.process()
        print(f"   âœ… æœ‰æ•ˆ track æ•°: {len(self.track_records)}")

        print("\n=== Stage 2: Feature Extraction ===")
        feature_extractor = TrackFeatureExtractor(self.metadata)
        self.features = feature_extractor.extract(self.track_records)
        print("   âœ… è½¨è¿¹ç‰¹å¾å®Œæˆ")

        print("\n=== Stage 3: æ„å»ºè¯æ®åŒ… ===")
        video_id = Path(self.config.video_path).stem
        self.evidence_map = build_evidence_packages(
            video_id, self.track_records, self.metadata, self.features
        )
        print(f"   âœ… æ„å»º {len(self.evidence_map)} ä¸ªè¯æ®åŒ…")

        self._persist_database()

    def question_search(self, question: str, *, top_k: int = 5, recall_limit: int | None = None):
        if self.evidence_map is None:
            raise RuntimeError("è¯·å…ˆè¿è¡Œ build_index()")

        print("\n=== æŸ¥è¯¢: é—®é¢˜é©±åŠ¨æ£€ç´¢ ===")
        print(f"æè¿°: {question}")

        candidates = self.recall_engine.recall(question, self.evidence_map, recall_limit)
        print(f"   ğŸ” å€™é€‰è½¨è¿¹æ•°: {len(candidates)}")

        vlm_results = self.vlm_client.answer(question, candidates)
        if not vlm_results:
            print("   âŒ æœªæ‰¾åˆ°åŒ¹é…è½¨è¿¹")
            return []

        vlm_results.sort(key=lambda r: r.score, reverse=True)
        selected = vlm_results[:top_k]

        print("   âœ… VLM åŒ¹é…ç»“æœ:")
        for item in selected:
            print(
                f"      - Track {item.track_id}: {item.start_s:.1f}s â†’ {item.end_s:.1f}s | ç†ç”±: {item.reason}"
            )

        track_ids = [item.track_id for item in selected]
        safe_name = question.replace(" ", "_")
        video_output = self.config.output_dir / f"tracking_{safe_name}.mp4"
        self.perception.render_highlight_video(
            self.track_records,
            self.metadata,
            track_ids,
            video_output,
            label_text=question,
        )

        return selected

    def _persist_database(self) -> None:
        db_path = self.config.output_dir / "semantic_database.json"
        feature_payload = (
            {str(tid): feature.to_dict() for tid, feature in self.features.items()}
            if self.features
            else {}
        )
        payload = {
            "video": str(self.config.video_path),
            "tracks": {
                str(tid): {
                    "frames": record.frames,
                    "bboxes": record.bboxes,
                    "crops": record.crops,
                }
                for tid, record in self.track_records.items()
            },
            "features": feature_payload,
        }
        with open(db_path, "w", encoding="utf-8") as f:
            json.dump(payload, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ’¾ æ•°æ®åº“å­˜å‚¨: {db_path}")


def run_demo() -> None:
    system = VideoSemanticSystem()
    system.build_index()

    print("\n=== Demo Queries ===")
    system.question_search("æ‰¾å‡ºç©¿ç´«è‰²è¡£æœçš„äºº", top_k=5)


if __name__ == "__main__":
    run_demo()
