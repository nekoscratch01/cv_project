# ğŸ­ Edge-Detective å·¥ä¸šåŒ–å‡çº§ç»ˆæè“å›¾ (Final Blueprint v1.0)

> **æ–‡æ¡£æ€§è´¨**: ç³»ç»Ÿæ¶æ„å†³ç­–è®°å½• (ADR) + å®æ–½ç»†åˆ™ + è®¾è®¡å“²å­¦å®£è¨€  
> **ç¼–å†™èƒŒæ™¯**: åŸºäº L4 GPU å®æµ‹æ•°æ®ï¼Œé’ˆå¯¹ Qwen3-VL-4B æ¨ç†ç“¶é¢ˆçš„æ·±åº¦åˆ†æä¸è§£å†³æ–¹æ¡ˆ  
> **æ ¸å¿ƒå‘ç°**: Batch å¤„ç†åœ¨å½“å‰æ¶æ„ä¸‹å®Œå…¨æ— æ•ˆï¼ˆ709s vs 697sï¼‰ï¼Œæ ¹å› æ˜¯è‡ªå›å½’ç”Ÿæˆçš„ä¸²è¡Œæœ¬è´¨  
> **ç›®æ ‡è¯»è€…**: ç³»ç»Ÿæ¶æ„å¸ˆã€ML Infra å·¥ç¨‹å¸ˆã€æœªæ¥çš„è‡ªå·±  

---

## ç›®å½•

1. [ç¬¬ä¸€ç« ï¼šé—®é¢˜æ ¹å› æ·±åº¦å‰–æ](#ç¬¬ä¸€ç« é—®é¢˜æ ¹å› æ·±åº¦å‰–æ)
2. [ç¬¬äºŒç« ï¼šè®¾è®¡å“²å­¦ä¸æ ¸å¿ƒåŸåˆ™](#ç¬¬äºŒç« è®¾è®¡å“²å­¦ä¸æ ¸å¿ƒåŸåˆ™)
3. [ç¬¬ä¸‰ç« ï¼šåˆ†å±‚æ¶æ„è¯¦ç»†è®¾è®¡](#ç¬¬ä¸‰ç« åˆ†å±‚æ¶æ„è¯¦ç»†è®¾è®¡)
4. [ç¬¬å››ç« ï¼šæ¨ç†å±‚å·¥ä¸šåŒ–æ–¹æ¡ˆ](#ç¬¬å››ç« æ¨ç†å±‚å·¥ä¸šåŒ–æ–¹æ¡ˆ)
5. [ç¬¬äº”ç« ï¼šé‡åŒ–æ¨¡å‹é›†æˆç­–ç•¥](#ç¬¬äº”ç« é‡åŒ–æ¨¡å‹é›†æˆç­–ç•¥)
6. [ç¬¬å…­ç« ï¼šæ•°æ®æµä¸å­˜å‚¨æ¶æ„](#ç¬¬å…­ç« æ•°æ®æµä¸å­˜å‚¨æ¶æ„)
7. [ç¬¬ä¸ƒç« ï¼šå‰ç«¯ä¸å¯è§†åŒ–è®¾è®¡](#ç¬¬ä¸ƒç« å‰ç«¯ä¸å¯è§†åŒ–è®¾è®¡)
8. [ç¬¬å…«ç« ï¼šå¯è§‚æµ‹æ€§ä¸è¿ç»´](#ç¬¬å…«ç« å¯è§‚æµ‹æ€§ä¸è¿ç»´)
9. [ç¬¬ä¹ç« ï¼šæ¼”è¿›è·¯çº¿å›¾](#ç¬¬ä¹ç« æ¼”è¿›è·¯çº¿å›¾)
10. [é™„å½•ï¼šå…³é”®ä»£ç å®ç°](#é™„å½•å…³é”®ä»£ç å®ç°)

---

## ç¬¬ä¸€ç« ï¼šé—®é¢˜æ ¹å› æ·±åº¦å‰–æ

### 1.1 å®æµ‹æ•°æ®å›é¡¾

åœ¨ L4 GPU (24GB VRAM) ä¸Šå¯¹ Qwen3-VL-4B è¿›è¡Œçš„åŸºå‡†æµ‹è¯•æ­ç¤ºäº†ä¸€ä¸ªæ®‹é…·çš„äº‹å®ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ€§èƒ½æµ‹è¯•ç»“æœæ±‡æ€»                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æµ‹è¯•åœºæ™¯          â”‚ å¤„ç†æ–¹å¼      â”‚ æ€»æ—¶é—´   â”‚ æ¯Trackå¹³å‡     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 7 Tracks          â”‚ Sequential    â”‚ 697s     â”‚ 99.6s           â”‚
â”‚ 7 Tracks          â”‚ Batch=4       â”‚ 710s     â”‚ 101.4s          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç»“è®º              â”‚ Batch åè€Œæ›´æ…¢ 13 ç§’ï¼                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ—¶é—´åˆ†è§£åˆ†æ

é€šè¿‡æ’æ¡©è®¡æ—¶ï¼Œæˆ‘ä»¬å¾—åˆ°äº†å•ä¸ª Track çš„å¤„ç†æ—¶é—´åˆ†è§£ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           å• Track å¤„ç†æ—¶é—´åˆ†è§£ (æ€»è®¡ ~100s)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  templates (chat_template)     â–ˆâ–ˆâ–ˆâ–ˆ 0.00s (0.00%)           â”‚
â”‚  images (Image.open)           â–ˆâ–ˆâ–ˆâ–ˆ 0.00s (0.00%)           â”‚
â”‚  proc (processor)              â–ˆâ–ˆâ–ˆâ–ˆ 0.35s (0.35%)           â”‚
â”‚  to_device (GPU transfer)      â–ˆâ–ˆâ–ˆâ–ˆ 0.07s (0.07%)           â”‚
â”‚  generate (autoregressive)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 99.5s   â”‚
â”‚                                           â†‘                  â”‚
â”‚                                    99.58% çš„æ—¶é—´ï¼           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 æ ¹å› é“¾æ¡

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Visual Tokens æ•°é‡çˆ†ç‚¸       â”‚
                    â”‚  (6å¼ å›¾ Ã— ~576 tokens = 3456)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      KV Cache æ˜¾å­˜å ç”¨å·¨å¤§       â”‚
                    â”‚   (æ¯ä¸ª token éœ€å­˜å‚¨ K å’Œ V)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   è‡ªå›å½’ç”Ÿæˆï¼šToken-by-Token     â”‚
                    â”‚   æ¯ä¸ª token å¿…é¡»ç­‰å‰ä¸€ä¸ªå®Œæˆ    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       Batch å†…æ— æ³•çœŸæ­£å¹¶è¡Œ       â”‚
                    â”‚  æœ€æ…¢çš„æ ·æœ¬å†³å®šæ•´ä¸ª Batch æ—¶é—´   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Padding æµªè´¹ + ä¼ªå¹¶è¡Œ        â”‚
                    â”‚      Batch=4 â‰ˆ Sequential       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.4 GPU æ˜¾å­˜æ›²çº¿è§£è¯»

```
æ˜¾å­˜ä½¿ç”¨æ—¶é—´çº¿ (å®æµ‹):

    18GB â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”
          â”‚                   â•±        â•²
          â”‚                  â•±          â•²    â† generate é˜¶æ®µ
          â”‚                 â•±            â•²      KV Cache å¢é•¿
     8GB â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•±              â•²  â† æ¨¡å‹æƒé‡ (æ’å®š)
          â”‚     â†‘          â†‘               â†“
    0GB â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â†’ æ—¶é—´
           åŠ è½½    CPUé¢„å¤„ç†     GPUæ¨ç†     é‡Šæ”¾
           
é—®é¢˜ï¼š8GB å¹³å°æœŸè¿‡é•¿ â†’ CPU é¢„å¤„ç†åœ¨ç­‰ GPU
      GPU åˆ©ç”¨ç‡ä½ â†’ ä¸æ˜¯ç®—åŠ›ç“¶é¢ˆï¼Œæ˜¯è°ƒåº¦ç“¶é¢ˆ
```

### 1.5 ä¸ºä»€ä¹ˆ HuggingFace transformers çš„ Batch æ— æ•ˆï¼Ÿ

```python
# HF transformers çš„ generate() å†…éƒ¨å®ç°ï¼ˆç®€åŒ–ï¼‰
def generate(input_ids, max_new_tokens):
    for step in range(max_new_tokens):
        # æ¯ä¸€æ­¥éƒ½æ˜¯å…¨åºåˆ— attention
        logits = model.forward(all_tokens)  # O(nÂ²) attention
        next_token = sample(logits[:, -1])
        all_tokens = concat(all_tokens, next_token)
        
        # Batch å†…ï¼šå¦‚æœæŸä¸ªæ ·æœ¬å·²ç”Ÿæˆ EOSï¼Œ
        # å®ƒä»ç„¶è¦ç­‰å…¶ä»–æ ·æœ¬å®Œæˆï¼
        # â†’ Padding æµªè´¹
```

**å…³é”®æ´å¯Ÿ**ï¼šHF çš„ `generate()` æ˜¯ä¸º"å•æ¬¡å¯¹è¯"è®¾è®¡çš„ï¼Œä¸æ˜¯ä¸º"é«˜ååæœåŠ¡"è®¾è®¡çš„ã€‚

---

## ç¬¬äºŒç« ï¼šè®¾è®¡å“²å­¦ä¸æ ¸å¿ƒåŸåˆ™

### 2.1 ç¬¬ä¸€æ€§åŸç†ï¼šå¼‚æ„è®¡ç®—çš„ç‰©ç†éš”ç¦»

**æ ¸å¿ƒçŸ›ç›¾**ï¼šCPU å–„äºå¤æ‚é€»è¾‘ï¼ŒGPU å–„äºå¹¶è¡Œè®¡ç®—ã€‚åœ¨åŒä¸€è¿›ç¨‹ä¸­æ··åˆä¸¤è€…ï¼Œå¿…ç„¶å¯¼è‡´ï¼š
- GIL é”äº‰æŠ¢ï¼ˆPython çš„åŸç½ªï¼‰
- æ˜¾å­˜ç¢ç‰‡åŒ–ï¼ˆæ¨¡å‹åŠ è½½ vs æ¨ç†ç¼“å­˜ï¼‰
- æ— æ³•ç‹¬ç«‹æ‰©ç¼©å®¹ï¼ˆä¸šåŠ¡å³°å€¼ â‰  æ¨ç†å³°å€¼ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼šç‰©ç†éš”ç¦» + ç½‘ç»œé€šä¿¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç‰©ç†éš”ç¦»æ¶æ„                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚   Control Plane   â”‚  HTTP   â”‚  Inference Plane  â”‚           â”‚
â”‚   â”‚   (Python/CPU)    â”‚ â”€â”€â”€â”€â”€â”€â–¶ â”‚    (vLLM/GPU)     â”‚           â”‚
â”‚   â”‚                   â”‚         â”‚                   â”‚           â”‚
â”‚   â”‚ â€¢ ä¸šåŠ¡é€»è¾‘        â”‚         â”‚ â€¢ æ¨¡å‹æ¨ç†        â”‚           â”‚
â”‚   â”‚ â€¢ è¯·æ±‚ç¼–æ’        â”‚         â”‚ â€¢ Continuous Batchâ”‚           â”‚
â”‚   â”‚ â€¢ æ•°æ®æ¸…æ´—        â”‚         â”‚ â€¢ KV Cache ç®¡ç†   â”‚           â”‚
â”‚   â”‚ â€¢ ç»“æœèšåˆ        â”‚         â”‚                   â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                              â”‚                      â”‚
â”‚           â”‚ SQL/S3                       â”‚ GPU Memory           â”‚
â”‚           â–¼                              â–¼                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚   Storage Plane   â”‚         â”‚   L4 GPU (24GB)   â”‚           â”‚
â”‚   â”‚ PostgreSQL/MinIO  â”‚         â”‚   ç‹¬å ï¼Œä¸å…±äº«     â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ä¾èµ–å€’ç½®åŸåˆ™ (DIP) çš„å·¥ç¨‹åŒ–è½åœ°

**é”™è¯¯ç¤ºèŒƒ**ï¼ˆå½“å‰ä»£ç ï¼‰ï¼š
```python
# video_semantic_search.py
from pipeline.vlm_client_hf import Qwen3VL4BHFClient  # ç›´æ¥ä¾èµ–å…·ä½“å®ç°

class VideoSemanticSystem:
    def _build_vlm_client(self):
        return Qwen3VL4BHFClient(self.config)  # ç¡¬ç¼–ç 
```

**æ­£ç¡®å§¿åŠ¿**ï¼ˆç›®æ ‡ä»£ç ï¼‰ï¼š
```python
# ports/inference.py (æŠ½è±¡æ¥å£)
from typing import Protocol

class InferencePort(Protocol):
    """æ¨ç†ç«¯å£ï¼šä¸šåŠ¡å±‚åªä¾èµ–æ­¤æ¥å£"""
    async def verify_track(
        self, 
        images: List[bytes], 
        prompt: str
    ) -> InferenceResult:
        ...

# adapters/vllm_adapter.py (å…·ä½“å®ç°)
class VllmAdapter:
    """vLLM é€‚é…å™¨ï¼šå®ç° InferencePort"""
    def __init__(self, endpoint: str):
        self.client = AsyncOpenAI(base_url=endpoint)
    
    async def verify_track(self, images, prompt) -> InferenceResult:
        # å…·ä½“å®ç°...

# adapters/quantized_adapter.py (å¦ä¸€ä¸ªå®ç°)
class QuantizedAdapter:
    """é‡åŒ–æ¨¡å‹é€‚é…å™¨ï¼šåŒæ ·å®ç° InferencePort"""
    def __init__(self, model_path: str):
        self.llm = Llama(model_path=model_path)
    
    async def verify_track(self, images, prompt) -> InferenceResult:
        # å…·ä½“å®ç°...
```

**æ”¶ç›Š**ï¼š
- ä¸šåŠ¡ä»£ç ä¸çŸ¥é“åº•å±‚æ˜¯ vLLM è¿˜æ˜¯é‡åŒ–æ¨¡å‹
- åˆ‡æ¢æ¨ç†åç«¯åªéœ€ä¿®æ”¹é…ç½®ï¼Œä»£ç é›¶æ”¹åŠ¨
- å¯ä»¥è¿è¡Œæ—¶åŠ¨æ€åˆ‡æ¢ï¼ˆA/B æµ‹è¯•ã€é™çº§ç­–ç•¥ï¼‰

### 2.3 åè…è´¥å±‚ (ACL) çš„å¿…è¦æ€§

VLM è¾“å‡ºçš„æ˜¯"è„æ•°æ®"ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ï¼Œå¿…é¡»åœ¨è¾¹ç•Œæ¸…æ´—ï¼š

```python
# è„æ•°æ®ç¤ºä¾‹ï¼ˆVLM å®é™…è¾“å‡ºï¼‰
"""
Based on the images provided, I can see a person wearing what appears to be 
a blue jacket. They seem to be walking from left to right across the frame.
The motion appears consistent with normal walking pace.

MATCH: yes
"""

# åè…è´¥å±‚è½¬æ¢
class VlmResponseParser:
    """ACLï¼šå°† VLM è„æ•°æ®è½¬æ¢ä¸ºé¢†åŸŸå€¼å¯¹è±¡"""
    
    def parse(self, raw_response: str) -> VerificationResult:
        # 1. æå–æ ¸å¿ƒåˆ¤æ–­
        match = self._extract_match_decision(raw_response)
        
        # 2. æå–ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
        confidence = self._extract_confidence(raw_response)
        
        # 3. å½’ä¸€åŒ–ä¸ºç³»ç»Ÿå†…éƒ¨çŠ¶æ€
        status = self._normalize_status(match, confidence)
        
        # 4. è¿”å›çº¯å‡€çš„å€¼å¯¹è±¡
        return VerificationResult(
            status=status,  # Enum: CONFIRMED | REJECTED | AMBIGUOUS
            confidence=confidence,
            raw_reason=raw_response
        )
```

### 2.4 é¢†åŸŸæ¨¡å‹çš„çº¯å‡€æ€§

```python
# é¢†åŸŸå®ä½“ï¼šåŒ…å«ä¸šåŠ¡è§„åˆ™
@dataclass
class Track:
    """è½¨è¿¹å®ä½“ï¼šæ ¸å¿ƒé¢†åŸŸå¯¹è±¡"""
    track_id: int
    video_id: str
    start_frame: int
    end_frame: int
    fps: float
    bboxes: List[BoundingBox]
    
    @property
    def duration_seconds(self) -> float:
        """ä¸šåŠ¡è§„åˆ™ï¼šæ—¶é•¿è®¡ç®—"""
        return (self.end_frame - self.start_frame) / self.fps
    
    @property
    def is_valid(self) -> bool:
        """ä¸šåŠ¡è§„åˆ™ï¼šæœ‰æ•ˆæ€§æ ¡éªŒ"""
        return (
            self.duration_seconds >= 0.5  # è‡³å°‘ 0.5 ç§’
            and len(self.bboxes) >= 3     # è‡³å°‘ 3 ä¸ªæ£€æµ‹ç‚¹
        )
    
    def compute_average_speed(self, frame_width: int) -> float:
        """ä¸šåŠ¡è§„åˆ™ï¼šé€Ÿåº¦å½’ä¸€åŒ–ï¼ˆç›¸å¯¹äºç”»é¢å®½åº¦ï¼‰"""
        if len(self.bboxes) < 2:
            return 0.0
        total_distance = sum(
            self._euclidean_distance(self.bboxes[i], self.bboxes[i+1])
            for i in range(len(self.bboxes) - 1)
        )
        return (total_distance / frame_width) / self.duration_seconds
```

---

## ç¬¬ä¸‰ç« ï¼šåˆ†å±‚æ¶æ„è¯¦ç»†è®¾è®¡

### 3.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ç”¨æˆ·å±‚ (User Layer)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Web å‰ç«¯      â”‚  â”‚   CLI å·¥å…·      â”‚  â”‚   API å®¢æˆ·ç«¯    â”‚          â”‚
â”‚  â”‚   (React)       â”‚  â”‚   (Click)       â”‚  â”‚   (SDK)         â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â”‚                    â”‚                    â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                    â”‚                    â”‚
            â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ç½‘å…³å±‚ (Gateway Layer)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                      FastAPI Gateway                           â”‚      â”‚
â”‚  â”‚  â€¢ è®¤è¯/æˆæƒ (JWT)                                             â”‚      â”‚
â”‚  â”‚  â€¢ è¯·æ±‚é™æµ (Rate Limiting)                                    â”‚      â”‚
â”‚  â”‚  â€¢ è¯·æ±‚è·¯ç”±                                                    â”‚      â”‚
â”‚  â”‚  â€¢ OpenAPI æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ                                        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       åº”ç”¨å±‚ (Application Layer)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  IndexUseCase   â”‚  â”‚  SearchUseCase  â”‚  â”‚ ReportUseCase   â”‚          â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚          â”‚
â”‚  â”‚  â€¢ è§†é¢‘è§£ç      â”‚  â”‚  â€¢ é—®é¢˜è§£æ     â”‚  â”‚  â€¢ ç»“æœèšåˆ     â”‚          â”‚
â”‚  â”‚  â€¢ æ£€æµ‹è¿½è¸ª     â”‚  â”‚  â€¢ å¬å›æ’åº     â”‚  â”‚  â€¢ è§†é¢‘ç”Ÿæˆ     â”‚          â”‚
â”‚  â”‚  â€¢ ç‰¹å¾æå–     â”‚  â”‚  â€¢ VLM éªŒè¯     â”‚  â”‚  â€¢ æŠ¥å‘Šå¯¼å‡º     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â”‚                    â”‚                    â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                    â”‚                    â”‚
            â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        é¢†åŸŸå±‚ (Domain Layer)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                        é¢†åŸŸå®ä½“ (Entities)                       â”‚    â”‚
â”‚  â”‚  â€¢ Video          â€¢ Track           â€¢ Evidence                  â”‚    â”‚
â”‚  â”‚  â€¢ Trajectory     â€¢ BoundingBox     â€¢ VerificationResult        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                        é¢†åŸŸæœåŠ¡ (Services)                       â”‚    â”‚
â”‚  â”‚  â€¢ TrackFeatureService    â€¢ MotionAnalyzer                      â”‚    â”‚
â”‚  â”‚  â€¢ EvidenceBuilder        â€¢ HardRuleEngine                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç«¯å£å±‚ (Ports Layer)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  InferencePort    â”‚  â”‚  StoragePort      â”‚  â”‚  VectorStorePort  â”‚    â”‚
â”‚  â”‚  (æ¨ç†æŠ½è±¡)       â”‚  â”‚  (å­˜å‚¨æŠ½è±¡)        â”‚  â”‚  (å‘é‡æ£€ç´¢æŠ½è±¡)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚            â”‚                      â”‚                      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚                      â”‚
             â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       é€‚é…å±‚ (Adapters Layer)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ VllmAdapter   â”‚  â”‚ QuantAdapter  â”‚  â”‚ CloudAdapter  â”‚  â† æ¨ç†é€‚é…å™¨  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ PostgresRepo  â”‚  â”‚ MinIOStorage  â”‚  â”‚ QdrantVector  â”‚  â† å­˜å‚¨é€‚é…å™¨  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚                      â”‚
             â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       åŸºç¡€è®¾æ–½å±‚ (Infrastructure)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ vLLM Server   â”‚  â”‚ PostgreSQL    â”‚  â”‚ Qdrant        â”‚                â”‚
â”‚  â”‚ (GPU ç‹¬å )    â”‚  â”‚ (å…ƒæ•°æ®)      â”‚  â”‚ (å‘é‡ç´¢å¼•)    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ MinIO         â”‚  â”‚ Redis         â”‚  â”‚ Prometheus    â”‚                â”‚
â”‚  â”‚ (å¯¹è±¡å­˜å‚¨)    â”‚  â”‚ (ç¼“å­˜/é˜Ÿåˆ—)   â”‚  â”‚ (ç›‘æ§æŒ‡æ ‡)    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ç›®å½•ç»“æ„è®¾è®¡

```
src/
â”œâ”€â”€ api/                          # ç½‘å…³å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # FastAPI å…¥å£
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ index.py              # POST /api/v1/videos
â”‚   â”‚   â”œâ”€â”€ search.py             # POST /api/v1/search
â”‚   â”‚   â”œâ”€â”€ tracks.py             # GET /api/v1/tracks/{id}
â”‚   â”‚   â””â”€â”€ health.py             # GET /health
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ requests.py           # Pydantic è¯·æ±‚æ¨¡å‹
â”‚   â”‚   â””â”€â”€ responses.py          # Pydantic å“åº”æ¨¡å‹
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ auth.py               # JWT è®¤è¯
â”‚   â”‚   â”œâ”€â”€ rate_limit.py         # é™æµ
â”‚   â”‚   â””â”€â”€ tracing.py            # é“¾è·¯è¿½è¸ª
â”‚   â””â”€â”€ dependencies.py           # ä¾èµ–æ³¨å…¥
â”‚
â”œâ”€â”€ application/                  # åº”ç”¨å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ use_cases/
â”‚   â”‚   â”œâ”€â”€ index_video.py        # è§†é¢‘ç´¢å¼•ç”¨ä¾‹
â”‚   â”‚   â”œâ”€â”€ search_tracks.py      # è½¨è¿¹æ£€ç´¢ç”¨ä¾‹
â”‚   â”‚   â””â”€â”€ generate_report.py    # æŠ¥å‘Šç”Ÿæˆç”¨ä¾‹
â”‚   â””â”€â”€ dto/                      # æ•°æ®ä¼ è¾“å¯¹è±¡
â”‚       â”œâ”€â”€ index_dto.py
â”‚       â””â”€â”€ search_dto.py
â”‚
â”œâ”€â”€ domain/                       # é¢†åŸŸå±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”œâ”€â”€ video.py              # è§†é¢‘å®ä½“
â”‚   â”‚   â”œâ”€â”€ track.py              # è½¨è¿¹å®ä½“
â”‚   â”‚   â””â”€â”€ evidence.py           # è¯æ®åŒ…å®ä½“
â”‚   â”œâ”€â”€ value_objects/
â”‚   â”‚   â”œâ”€â”€ bounding_box.py       # è¾¹ç•Œæ¡†å€¼å¯¹è±¡
â”‚   â”‚   â”œâ”€â”€ trajectory.py         # è½¨è¿¹å€¼å¯¹è±¡
â”‚   â”‚   â””â”€â”€ verification_result.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py  # ç‰¹å¾æå–æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ motion_analyzer.py    # è¿åŠ¨åˆ†ææœåŠ¡
â”‚   â”‚   â””â”€â”€ hard_rule_engine.py   # ç¡¬è§„åˆ™å¼•æ“
â”‚   â””â”€â”€ events/
â”‚       â””â”€â”€ domain_events.py      # é¢†åŸŸäº‹ä»¶
â”‚
â”œâ”€â”€ ports/                        # ç«¯å£å±‚ (æŠ½è±¡æ¥å£)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference_port.py         # æ¨ç†ç«¯å£
â”‚   â”œâ”€â”€ storage_port.py           # å­˜å‚¨ç«¯å£
â”‚   â”œâ”€â”€ vector_store_port.py      # å‘é‡å­˜å‚¨ç«¯å£
â”‚   â””â”€â”€ message_queue_port.py     # æ¶ˆæ¯é˜Ÿåˆ—ç«¯å£
â”‚
â”œâ”€â”€ adapters/                     # é€‚é…å±‚ (å…·ä½“å®ç°)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ vllm_adapter.py       # vLLM é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ quantized_adapter.py  # é‡åŒ–æ¨¡å‹é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ openai_adapter.py     # OpenAI API é€‚é…å™¨
â”‚   â”‚   â””â”€â”€ response_parser.py    # VLM å“åº”è§£æå™¨ (ACL)
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ postgres_repo.py      # PostgreSQL ä»“å‚¨
â”‚   â”‚   â””â”€â”€ minio_storage.py      # MinIO å¯¹è±¡å­˜å‚¨
â”‚   â”œâ”€â”€ vector/
â”‚   â”‚   â””â”€â”€ qdrant_adapter.py     # Qdrant å‘é‡åº“
â”‚   â””â”€â”€ detection/
â”‚       â””â”€â”€ yolo_adapter.py       # YOLO æ£€æµ‹é€‚é…å™¨
â”‚
â”œâ”€â”€ infrastructure/               # åŸºç¡€è®¾æ–½é…ç½®
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ app_config.py         # åº”ç”¨é…ç½®
â”‚   â”‚   â””â”€â”€ infra_config.py       # åŸºç¡€è®¾æ–½é…ç½®
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py             # SQLAlchemy æ¨¡å‹
â”‚   â”‚   â””â”€â”€ migrations/           # Alembic è¿ç§»
â”‚   â””â”€â”€ logging/
â”‚       â””â”€â”€ structured_logger.py  # ç»“æ„åŒ–æ—¥å¿—
â”‚
â”œâ”€â”€ tasks/                        # å¼‚æ­¥ä»»åŠ¡
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ celery_app.py             # Celery é…ç½®
â”‚   â””â”€â”€ indexing.py               # ç´¢å¼•ä»»åŠ¡
â”‚
â””â”€â”€ tests/                        # æµ‹è¯•
    â”œâ”€â”€ unit/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

---

## ç¬¬å››ç« ï¼šæ¨ç†å±‚å·¥ä¸šåŒ–æ–¹æ¡ˆ

### 4.1 vLLM é€‰å‹ç†ç”±

| ç‰¹æ€§ | HF transformers | vLLM | è¯´æ˜ |
|------|-----------------|------|------|
| Batching ç­–ç•¥ | Static Padding | **Continuous Batching** | æ— éœ€å¯¹é½ï¼Œæ—  padding æµªè´¹ |
| å†…å­˜ç®¡ç† | PyTorch é»˜è®¤ | **PagedAttention** | KV Cache åˆ†é¡µï¼Œæ˜¾å­˜åˆ©ç”¨ç‡é«˜ |
| å¹¶å‘å¤„ç† | ä¸²è¡Œæˆ–ä¼ªå¹¶è¡Œ | **çœŸæ­£å¹¶è¡Œ** | å¤šè¯·æ±‚åŒæ—¶å¤„ç† |
| ååé‡ | 1x | **3-5x** | å®æµ‹æ•°æ® |
| è°ƒè¯•ä½“éªŒ | æ¯æ¬¡é‡è½½æ¨¡å‹ | **æœåŠ¡å¸¸é©»** | æ”¹ä»£ç ä¸ç”¨ç­‰åŠ è½½ |

### 4.2 vLLM æœåŠ¡éƒ¨ç½²é…ç½®

```bash
#!/bin/bash
# deploy/start_vllm.sh

# ç”Ÿäº§çº§é…ç½®å‚æ•°è¯¦è§£
python -m vllm.entrypoints.openai.api_server \
    # æ¨¡å‹æ ‡è¯†
    --model Qwen/Qwen3-VL-4B-Instruct \
    --trust-remote-code \
    
    # ç½‘ç»œé…ç½®
    --host 0.0.0.0 \
    --port 8000 \
    
    # æ˜¾å­˜ç®¡ç†
    --gpu-memory-utilization 0.90 \        # ä½¿ç”¨ 90% æ˜¾å­˜ï¼Œç•™ 10% ç»™ OS
    
    # ä¸Šä¸‹æ–‡é•¿åº¦
    --max-model-len 8192 \                 # æœ€å¤§ 8K tokens
    
    # å¤šæ¨¡æ€é™åˆ¶
    --limit-mm-per-prompt image=5 \        # æ¯ä¸ªè¯·æ±‚æœ€å¤š 5 å¼ å›¾
    
    # æ€§èƒ½ä¼˜åŒ–
    --enable-prefix-caching \              # ç›¸åŒå‰ç¼€çš„ prompt å…±äº« KV Cache
    --disable-log-requests \               # ç”Ÿäº§ç¯å¢ƒå…³é—­è¯·æ±‚æ—¥å¿—
    
    # é‡åŒ–ï¼ˆå¯é€‰ï¼‰
    # --quantization awq \                 # ä½¿ç”¨ AWQ é‡åŒ–
    
    # å¼ é‡å¹¶è¡Œï¼ˆå¤šå¡ï¼‰
    # --tensor-parallel-size 2 \           # 2 å¡å¹¶è¡Œ
```

### 4.3 vLLM å®¢æˆ·ç«¯å®ç°

```python
# adapters/inference/vllm_adapter.py

import base64
import asyncio
from typing import List, Optional
from openai import AsyncOpenAI
from dataclasses import dataclass

from ports.inference_port import InferencePort, InferenceResult
from domain.entities.evidence import EvidencePackage


@dataclass
class VllmConfig:
    """vLLM é…ç½®"""
    endpoint: str = "http://localhost:8000/v1"
    model_name: str = "Qwen/Qwen3-VL-4B-Instruct"
    temperature: float = 0.1
    max_tokens: int = 256
    timeout: float = 120.0
    max_retries: int = 3
    max_images_per_request: int = 5


class VllmAdapter(InferencePort):
    """
    vLLM æ¨ç†é€‚é…å™¨
    
    è®¾è®¡è¦ç‚¹ï¼š
    1. å®Œå…¨æ— çŠ¶æ€ - å¯ä»¥åœ¨å¤šä¸ª worker é—´å…±äº«
    2. å¼‚æ­¥ä¼˜å…ˆ - æ”¯æŒé«˜å¹¶å‘
    3. é‡è¯•æœºåˆ¶ - ç½‘ç»œæŠ–åŠ¨å®¹é”™
    4. è¶…æ—¶æ§åˆ¶ - é˜²æ­¢è¯·æ±‚å †ç§¯
    """
    
    def __init__(self, config: VllmConfig):
        self.config = config
        self.client = AsyncOpenAI(
            base_url=config.endpoint,
            api_key="EMPTY",  # vLLM ä¸éœ€è¦çœŸå® API Key
            timeout=config.timeout,
            max_retries=config.max_retries,
        )
        self._response_parser = VlmResponseParser()
    
    async def verify_track(
        self,
        package: EvidencePackage,
        question: str,
        plan_context: Optional[str] = None,
    ) -> InferenceResult:
        """
        éªŒè¯å•ä¸ªè½¨è¿¹æ˜¯å¦åŒ¹é…æŸ¥è¯¢
        
        Args:
            package: è¯æ®åŒ…ï¼ˆåŒ…å«å›¾ç‰‡è·¯å¾„ã€ç‰¹å¾ç­‰ï¼‰
            question: ç”¨æˆ·æŸ¥è¯¢
            plan_context: Router ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            InferenceResult: åŒ…å« match åˆ¤æ–­ã€ç½®ä¿¡åº¦ã€åŸå› 
        """
        # 1. æ„é€ æ¶ˆæ¯
        messages = self._build_messages(package, question, plan_context)
        
        # 2. è°ƒç”¨ vLLM
        response = await self.client.chat.completions.create(
            model=self.config.model_name,
            messages=messages,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens,
        )
        
        # 3. è§£æå“åº”ï¼ˆACL å±‚ï¼‰
        raw_text = response.choices[0].message.content
        return self._response_parser.parse(raw_text)
    
    async def verify_batch(
        self,
        packages: List[EvidencePackage],
        question: str,
        plan_context: Optional[str] = None,
        concurrency: int = 10,
    ) -> List[InferenceResult]:
        """
        æ‰¹é‡éªŒè¯è½¨è¿¹ï¼ˆçœŸæ­£çš„å¹¶å‘ï¼‰
        
        ä¸ HF transformers çš„ Batch ä¸åŒï¼š
        - HF Batch: åŒä¸€ä¸ª forward passï¼Œå— padding å½±å“
        - vLLM å¹¶å‘: å¤šä¸ªç‹¬ç«‹è¯·æ±‚ï¼ŒvLLM å†…éƒ¨ Continuous Batching
        
        Args:
            packages: è¯æ®åŒ…åˆ—è¡¨
            question: ç”¨æˆ·æŸ¥è¯¢
            plan_context: ä¸Šä¸‹æ–‡
            concurrency: å¹¶å‘æ•°é™åˆ¶ï¼ˆé˜²æ­¢å‹å®æœåŠ¡ï¼‰
        """
        semaphore = asyncio.Semaphore(concurrency)
        
        async def _verify_with_limit(pkg: EvidencePackage) -> InferenceResult:
            async with semaphore:
                return await self.verify_track(pkg, question, plan_context)
        
        # çœŸæ­£çš„å¹¶è¡Œï¼
        tasks = [_verify_with_limit(pkg) for pkg in packages]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸
        processed = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Track {packages[i].track_id} failed: {result}")
                processed.append(InferenceResult.error(str(result)))
            else:
                processed.append(result)
        
        return processed
    
    def _build_messages(
        self,
        package: EvidencePackage,
        question: str,
        plan_context: Optional[str],
    ) -> List[dict]:
        """æ„é€  OpenAI æ ¼å¼çš„æ¶ˆæ¯"""
        # é‡‡æ ·å›¾ç‰‡ï¼ˆæœ€å¤š max_images_per_request å¼ ï¼‰
        crop_paths = self._sample_crops(package.crops)
        
        # ç¼–ç å›¾ç‰‡ä¸º base64
        image_contents = []
        for path in crop_paths:
            base64_image = self._encode_image(path)
            image_contents.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            })
        
        # æ„é€  prompt
        prompt = self._build_prompt(package, question, plan_context)
        
        return [
            {
                "role": "system",
                "content": "You are a video analysis assistant. Answer with reasoning, then end with 'MATCH: yes' or 'MATCH: no'."
            },
            {
                "role": "user",
                "content": [
                    *image_contents,
                    {"type": "text", "text": prompt}
                ]
            }
        ]
    
    def _sample_crops(self, crops: List[str]) -> List[str]:
        """è´¨é‡ä¼˜å…ˆçš„å‡åŒ€é‡‡æ ·"""
        max_crops = self.config.max_images_per_request
        if len(crops) <= max_crops:
            return crops
        
        # å‡åŒ€é‡‡æ ·
        step = len(crops) / max_crops
        indices = [int(i * step) for i in range(max_crops)]
        return [crops[i] for i in indices]
    
    @staticmethod
    def _encode_image(path: str) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸º base64"""
        with open(path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    
    def _build_prompt(
        self,
        package: EvidencePackage,
        question: str,
        plan_context: Optional[str],
    ) -> str:
        """æ„é€ éªŒè¯ prompt"""
        motion_desc = self._build_motion_description(package)
        
        prompt = f"""## Task
Verify if this person matches the query: "{question}"

## Evidence
### Appearance
The images show the person at different moments in the video.

### Motion Summary
{motion_desc}

### Constraints
{plan_context or "No additional constraints."}

## Instructions
1. Describe what you see in the images.
2. Check if the person matches the query criteria.
3. Final line must be: MATCH: yes or MATCH: no
"""
        return prompt
    
    def _build_motion_description(self, package: EvidencePackage) -> str:
        """æ„å»ºè¿åŠ¨æè¿°"""
        if not package.features:
            return "No motion data available."
        
        feats = package.features
        parts = []
        
        # é€Ÿåº¦æè¿°
        if feats.avg_speed_px_s < 50:
            parts.append("Standing still or barely moving")
        elif feats.avg_speed_px_s < 200:
            parts.append("Walking at normal pace")
        else:
            parts.append("Moving fast or running")
        
        # æ–¹å‘æè¿°
        dx, dy = feats.displacement_vec
        if abs(dx) > abs(dy):
            direction = "right" if dx > 0 else "left"
        else:
            direction = "down (towards camera)" if dy > 0 else "up (away)"
        parts.append(f"Moving {direction}")
        
        # æ—¶é•¿
        parts.append(f"Duration: {package.duration_seconds:.1f}s")
        
        return ". ".join(parts) + "."
```

### 4.4 å“åº”è§£æå™¨ï¼ˆåè…è´¥å±‚ï¼‰

```python
# adapters/inference/response_parser.py

import re
from enum import Enum
from dataclasses import dataclass
from typing import Tuple


class MatchStatus(Enum):
    """åŒ¹é…çŠ¶æ€æšä¸¾"""
    CONFIRMED = "confirmed"      # ç¡®è®¤åŒ¹é…
    REJECTED = "rejected"        # ç¡®è®¤ä¸åŒ¹é…
    AMBIGUOUS = "ambiguous"      # æ¨¡ç³Š/æ— æ³•åˆ¤æ–­


@dataclass
class InferenceResult:
    """æ¨ç†ç»“æœå€¼å¯¹è±¡"""
    status: MatchStatus
    confidence: float
    reason: str
    raw_response: str
    
    @classmethod
    def error(cls, error_msg: str) -> "InferenceResult":
        return cls(
            status=MatchStatus.AMBIGUOUS,
            confidence=0.0,
            reason=f"Error: {error_msg}",
            raw_response=""
        )
    
    @property
    def is_match(self) -> bool:
        return self.status == MatchStatus.CONFIRMED


class VlmResponseParser:
    """
    VLM å“åº”è§£æå™¨ï¼ˆåè…è´¥å±‚å®ç°ï¼‰
    
    èŒè´£ï¼š
    1. ä»è‡ªç„¶è¯­è¨€å“åº”ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
    2. å¤„ç†å„ç§è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æ ¼å¼
    3. å°†ä¸å¯é çš„å¤–éƒ¨æ•°æ®è½¬æ¢ä¸ºå¯é çš„å†…éƒ¨è¡¨ç¤º
    """
    
    # æ­£åˆ™æ¨¡å¼
    MATCH_PATTERN = re.compile(r"MATCH:\s*(yes|no)", re.IGNORECASE)
    CONFIDENCE_PATTERN = re.compile(r"confidence[:\s]+(\d+(?:\.\d+)?)", re.IGNORECASE)
    
    def parse(self, raw_response: str) -> InferenceResult:
        """
        è§£æ VLM åŸå§‹å“åº”
        
        è§£æä¼˜å…ˆçº§ï¼š
        1. æ˜¾å¼çš„ "MATCH: yes/no" æ ‡è®°
        2. è‡ªç„¶è¯­è¨€ä¸­çš„ yes/no å…³é”®è¯
        3. å¦å®šè¯æ£€æµ‹
        4. é»˜è®¤ä¸ºæ¨¡ç³ŠçŠ¶æ€
        """
        if not raw_response:
            return InferenceResult.error("Empty response")
        
        # å°è¯•æå–æ˜¾å¼ MATCH æ ‡è®°
        match_result = self._extract_match_marker(raw_response)
        
        # å°è¯•æå–ç½®ä¿¡åº¦
        confidence = self._extract_confidence(raw_response)
        
        # ç¡®å®šæœ€ç»ˆçŠ¶æ€
        status = self._determine_status(match_result, confidence)
        
        return InferenceResult(
            status=status,
            confidence=confidence,
            reason=self._extract_reason(raw_response),
            raw_response=raw_response
        )
    
    def _extract_match_marker(self, text: str) -> bool | None:
        """æå–æ˜¾å¼ MATCH æ ‡è®°"""
        match = self.MATCH_PATTERN.search(text)
        if match:
            return match.group(1).lower() == "yes"
        return None
    
    def _extract_confidence(self, text: str) -> float:
        """æå–ç½®ä¿¡åº¦"""
        match = self.CONFIDENCE_PATTERN.search(text)
        if match:
            try:
                conf = float(match.group(1))
                return min(max(conf, 0.0), 1.0)  # å½’ä¸€åŒ–åˆ° [0, 1]
            except ValueError:
                pass
        
        # é»˜è®¤ç½®ä¿¡åº¦åŸºäºæ˜¯å¦æœ‰æ˜ç¡®åˆ¤æ–­
        return 0.8 if self._extract_match_marker(text) is not None else 0.5
    
    def _determine_status(
        self,
        match_result: bool | None,
        confidence: float
    ) -> MatchStatus:
        """æ ¹æ®è§£æç»“æœç¡®å®šæœ€ç»ˆçŠ¶æ€"""
        if match_result is True and confidence >= 0.6:
            return MatchStatus.CONFIRMED
        elif match_result is False:
            return MatchStatus.REJECTED
        else:
            return MatchStatus.AMBIGUOUS
    
    def _extract_reason(self, text: str) -> str:
        """æå–æ¨ç†ç†ç”±"""
        # å»æ‰ MATCH è¡Œï¼Œä¿ç•™è§£é‡Šéƒ¨åˆ†
        lines = text.strip().split("\n")
        reason_lines = [
            line for line in lines
            if not line.strip().lower().startswith("match:")
        ]
        return " ".join(reason_lines).strip()[:500]  # é™åˆ¶é•¿åº¦
```

---

## ç¬¬äº”ç« ï¼šé‡åŒ–æ¨¡å‹é›†æˆç­–ç•¥

### 5.1 é‡åŒ–æ–¹æ¡ˆé€‰å‹

| æ–¹æ¡ˆ | æ˜¾å­˜å ç”¨ | é€Ÿåº¦ | ç²¾åº¦æŸå¤± | é€‚ç”¨åœºæ™¯ |
|------|----------|------|----------|----------|
| FP16 (åŸå§‹) | 8GB | 1x | 0% | åŸºå‡†/é«˜ç²¾åº¦éœ€æ±‚ |
| **AWQ (4-bit)** | 2-3GB | 2-3x | 1-3% | **æ¨èï¼šè¾¹ç¼˜/æˆæœ¬æ•æ„Ÿ** |
| GPTQ (4-bit) | 2-3GB | 2x | 2-4% | å¤‡é€‰ |
| GGUF (llama.cpp) | 2-4GB | 1.5-2x | 2-5% | CPU æ¨ç†/æåº¦èµ„æºå—é™ |

### 5.2 é‡åŒ–æ¨¡å‹é€‚é…å™¨

```python
# adapters/inference/quantized_adapter.py

from typing import List, Optional
from llama_cpp import Llama
from llama_cpp.llama_chat_format import Llava15ChatHandler

from ports.inference_port import InferencePort, InferenceResult


class QuantizedConfig:
    """é‡åŒ–æ¨¡å‹é…ç½®"""
    model_path: str = "models/qwen2-vl-7b-awq-q4.gguf"
    clip_model_path: str = "models/qwen2-vl-clip.gguf"
    n_ctx: int = 4096
    n_gpu_layers: int = -1  # -1 = å…¨éƒ¨åŠ è½½åˆ° GPU
    n_threads: int = 4


class QuantizedAdapter(InferencePort):
    """
    é‡åŒ–æ¨¡å‹é€‚é…å™¨
    
    ä½¿ç”¨ llama.cpp ä½œä¸ºåç«¯ï¼Œæ”¯æŒï¼š
    - GGUF æ ¼å¼çš„é‡åŒ–æ¨¡å‹
    - æ··åˆ CPU/GPU æ¨ç†
    - æä½æ˜¾å­˜å ç”¨
    
    é€‚ç”¨åœºæ™¯ï¼š
    - è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ï¼ˆJetsonã€æ ‘è“æ´¾ï¼‰
    - æˆæœ¬æ•æ„Ÿåœºæ™¯
    - ç¦»çº¿ç¯å¢ƒ
    """
    
    def __init__(self, config: QuantizedConfig):
        self.config = config
        
        # åˆå§‹åŒ–è§†è§‰å¤„ç†å™¨
        self.chat_handler = Llava15ChatHandler(
            clip_model_path=config.clip_model_path
        )
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.llm = Llama(
            model_path=config.model_path,
            n_ctx=config.n_ctx,
            n_gpu_layers=config.n_gpu_layers,
            n_threads=config.n_threads,
            chat_handler=self.chat_handler,
            logits_all=True,
            verbose=False,
        )
        
        self._response_parser = VlmResponseParser()
    
    async def verify_track(
        self,
        package: EvidencePackage,
        question: str,
        plan_context: Optional[str] = None,
    ) -> InferenceResult:
        """éªŒè¯å•ä¸ªè½¨è¿¹"""
        # æ„é€ æ¶ˆæ¯
        messages = self._build_messages(package, question, plan_context)
        
        # åŒæ­¥è°ƒç”¨ï¼ˆllama.cpp ä¸æ”¯æŒåŸç”Ÿå¼‚æ­¥ï¼‰
        # ä½¿ç”¨ run_in_executor åŒ…è£…
        import asyncio
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: self.llm.create_chat_completion(
                messages=messages,
                max_tokens=256,
                temperature=0.1,
            )
        )
        
        # è§£æå“åº”
        raw_text = response["choices"][0]["message"]["content"]
        return self._response_parser.parse(raw_text)
    
    def _build_messages(self, package, question, plan_context):
        """æ„é€  llama.cpp æ ¼å¼çš„æ¶ˆæ¯"""
        # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
        crop_paths = package.crops[:3]  # é‡åŒ–æ¨¡å‹ç”¨æ›´å°‘çš„å›¾
        image_data = []
        for path in crop_paths:
            with open(path, "rb") as f:
                image_data.append(f.read())
        
        # llama.cpp çš„æ¶ˆæ¯æ ¼å¼
        return [
            {
                "role": "system",
                "content": "You are a video analysis assistant."
            },
            {
                "role": "user",
                "content": [
                    *[{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64.b64encode(img).decode()}"}} for img in image_data],
                    {"type": "text", "text": f"Query: {question}\n\nDoes this person match? Answer with MATCH: yes or MATCH: no"}
                ]
            }
        ]
```

### 5.3 æ¨ç†ç­–ç•¥è·¯ç”±å™¨

```python
# adapters/inference/model_registry.py

from enum import Enum
from typing import Dict

from ports.inference_port import InferencePort


class InferencePriority(Enum):
    """æ¨ç†ä¼˜å…ˆçº§"""
    HIGH_ACCURACY = "high_accuracy"    # é«˜ç²¾åº¦ä¼˜å…ˆ
    LOW_LATENCY = "low_latency"        # ä½å»¶è¿Ÿä¼˜å…ˆ
    COST_SAVING = "cost_saving"        # æˆæœ¬ä¼˜å…ˆ


class ModelRegistry:
    """
    æ¨¡å‹æ³¨å†Œä¸­å¿ƒ
    
    èŒè´£ï¼š
    1. ç®¡ç†å¤šä¸ªæ¨ç†é€‚é…å™¨
    2. æ ¹æ®ç­–ç•¥è·¯ç”±è¯·æ±‚
    3. æ”¯æŒè¿è¡Œæ—¶åˆ‡æ¢
    4. å®ç° A/B æµ‹è¯•
    """
    
    def __init__(self):
        self._adapters: Dict[str, InferencePort] = {}
        self._priority_map: Dict[InferencePriority, str] = {}
    
    def register(
        self,
        name: str,
        adapter: InferencePort,
        priorities: List[InferencePriority] = None
    ):
        """æ³¨å†Œé€‚é…å™¨"""
        self._adapters[name] = adapter
        
        if priorities:
            for priority in priorities:
                self._priority_map[priority] = name
    
    def get_adapter(
        self,
        priority: InferencePriority = InferencePriority.HIGH_ACCURACY
    ) -> InferencePort:
        """æ ¹æ®ä¼˜å…ˆçº§è·å–é€‚é…å™¨"""
        adapter_name = self._priority_map.get(priority)
        if not adapter_name or adapter_name not in self._adapters:
            raise ValueError(f"No adapter registered for priority: {priority}")
        return self._adapters[adapter_name]
    
    def get_by_name(self, name: str) -> InferencePort:
        """æŒ‰åç§°è·å–é€‚é…å™¨"""
        if name not in self._adapters:
            raise ValueError(f"Adapter not found: {name}")
        return self._adapters[name]


# åˆå§‹åŒ–ç¤ºä¾‹
def create_model_registry(config: AppConfig) -> ModelRegistry:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæ¨¡å‹æ³¨å†Œä¸­å¿ƒ"""
    registry = ModelRegistry()
    
    # æ³¨å†Œ vLLMï¼ˆé«˜ç²¾åº¦ï¼‰
    if config.vllm_enabled:
        vllm_adapter = VllmAdapter(VllmConfig(
            endpoint=config.vllm_endpoint,
            model_name=config.vllm_model_name,
        ))
        registry.register(
            "vllm",
            vllm_adapter,
            [InferencePriority.HIGH_ACCURACY]
        )
    
    # æ³¨å†Œé‡åŒ–æ¨¡å‹ï¼ˆæˆæœ¬ä¼˜å…ˆï¼‰
    if config.quantized_enabled:
        quant_adapter = QuantizedAdapter(QuantizedConfig(
            model_path=config.quantized_model_path,
        ))
        registry.register(
            "quantized",
            quant_adapter,
            [InferencePriority.COST_SAVING, InferencePriority.LOW_LATENCY]
        )
    
    # æ³¨å†Œäº‘ç«¯ APIï¼ˆå¤‡ä»½ï¼‰
    if config.cloud_api_enabled:
        cloud_adapter = CloudApiAdapter(config.cloud_api_key)
        registry.register("cloud", cloud_adapter)
    
    return registry
```

### 5.4 åŠ¨æ€åˆ‡æ¢ä¸ A/B æµ‹è¯•

```python
# application/use_cases/search_tracks.py

class SearchTracksUseCase:
    """è½¨è¿¹æ£€ç´¢ç”¨ä¾‹"""
    
    def __init__(
        self,
        model_registry: ModelRegistry,
        feature_toggle: FeatureToggle,  # ç‰¹æ€§å¼€å…³æœåŠ¡
    ):
        self.model_registry = model_registry
        self.feature_toggle = feature_toggle
    
    async def execute(
        self,
        request: SearchRequest
    ) -> SearchResponse:
        # æ ¹æ®ç‰¹æ€§å¼€å…³å†³å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹
        model_strategy = self.feature_toggle.get_strategy("vlm_model")
        
        if model_strategy == "ab_test":
            # A/B æµ‹è¯•ï¼š50% æµé‡ç”¨ vLLMï¼Œ50% ç”¨é‡åŒ–æ¨¡å‹
            import random
            if random.random() < 0.5:
                adapter = self.model_registry.get_by_name("vllm")
                model_variant = "vllm"
            else:
                adapter = self.model_registry.get_by_name("quantized")
                model_variant = "quantized"
        elif model_strategy == "cost_saving":
            adapter = self.model_registry.get_adapter(InferencePriority.COST_SAVING)
            model_variant = "quantized"
        else:
            adapter = self.model_registry.get_adapter(InferencePriority.HIGH_ACCURACY)
            model_variant = "vllm"
        
        # æ‰§è¡Œæ£€ç´¢
        results = await self._search_with_adapter(adapter, request)
        
        # è®°å½• A/B æµ‹è¯•æŒ‡æ ‡
        metrics.record_search(
            model_variant=model_variant,
            latency=results.latency,
            match_count=len(results.matches),
        )
        
        return results
```

---

## ç¬¬å…­ç« ï¼šæ•°æ®æµä¸å­˜å‚¨æ¶æ„

### 6.1 æ•°æ®åˆ†çº§å­˜å‚¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ•°æ®åˆ†çº§å­˜å‚¨ç­–ç•¥                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Hot (L1) - Redis                                        â”‚    â”‚
â”‚  â”‚  â€¢ å®æ—¶ä»»åŠ¡çŠ¶æ€ (TTL: 1h)                                â”‚    â”‚
â”‚  â”‚  â€¢ æœ€è¿‘æ£€ç´¢ç»“æœç¼“å­˜ (TTL: 10min)                         â”‚    â”‚
â”‚  â”‚  â€¢ WebSocket ä¼šè¯çŠ¶æ€                                    â”‚    â”‚
â”‚  â”‚  â€¢ è¯»å»¶è¿Ÿ: <1ms                                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Warm (L2) - Qdrant                                      â”‚    â”‚
â”‚  â”‚  â€¢ è½¨è¿¹ Embedding å‘é‡ (768d)                            â”‚    â”‚
â”‚  â”‚  â€¢ è½»é‡çº§ Payload (track_id, video_id, time_range)       â”‚    â”‚
â”‚  â”‚  â€¢ å¸¸é©»å†…å­˜/NVMe SSD                                     â”‚    â”‚
â”‚  â”‚  â€¢ æ£€ç´¢å»¶è¿Ÿ: 10-50ms                                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Cold (L3) - PostgreSQL + MinIO                          â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  PostgreSQL:                                             â”‚    â”‚
â”‚  â”‚    â€¢ è§†é¢‘å…ƒæ•°æ® (Video)                                  â”‚    â”‚
â”‚  â”‚    â€¢ è½¨è¿¹è¯¦æƒ… (Track)                                    â”‚    â”‚
â”‚  â”‚    â€¢ æ£€ç´¢å†å² (SearchLog)                                â”‚    â”‚
â”‚  â”‚    â€¢ ç”¨æˆ·å®¡è®¡ (AuditLog)                                 â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  MinIO:                                                  â”‚    â”‚
â”‚  â”‚    â€¢ åŸå§‹è§†é¢‘æ–‡ä»¶ (videos/)                              â”‚    â”‚
â”‚  â”‚    â€¢ è½¨è¿¹æˆªå›¾ (crops/{video_id}/{track_id}/)             â”‚    â”‚
â”‚  â”‚    â€¢ ç”Ÿæˆçš„é«˜äº®è§†é¢‘ (outputs/)                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 æ•°æ®åº“ Schema è®¾è®¡

```python
# infrastructure/database/models.py

from sqlalchemy import Column, Integer, String, Float, JSON, DateTime, Enum, ForeignKey
from sqlalchemy.orm import relationship
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()


class Video(Base):
    """è§†é¢‘å®ä½“è¡¨"""
    __tablename__ = "videos"
    
    id = Column(String(36), primary_key=True)  # UUID
    original_path = Column(String(512), nullable=False)
    storage_path = Column(String(512))  # MinIO path
    
    # å…ƒæ•°æ®
    fps = Column(Float, nullable=False)
    width = Column(Integer, nullable=False)
    height = Column(Integer, nullable=False)
    total_frames = Column(Integer, nullable=False)
    duration_seconds = Column(Float, nullable=False)
    
    # çŠ¶æ€
    status = Column(
        Enum("pending", "processing", "completed", "failed", name="video_status"),
        default="pending"
    )
    error_message = Column(String(1024))
    
    # æ—¶é—´æˆ³
    created_at = Column(DateTime, server_default="now()")
    updated_at = Column(DateTime, onupdate="now()")
    
    # å…³è”
    tracks = relationship("Track", back_populates="video", cascade="all, delete-orphan")


class Track(Base):
    """è½¨è¿¹å®ä½“è¡¨"""
    __tablename__ = "tracks"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    video_id = Column(String(36), ForeignKey("videos.id", ondelete="CASCADE"))
    local_track_id = Column(Integer, nullable=False)  # è§†é¢‘å†…å”¯ä¸€çš„ track_id
    
    # æ—¶é—´èŒƒå›´
    start_frame = Column(Integer, nullable=False)
    end_frame = Column(Integer, nullable=False)
    start_seconds = Column(Float, nullable=False)
    end_seconds = Column(Float, nullable=False)
    duration_seconds = Column(Float, nullable=False)
    
    # è¿åŠ¨ç‰¹å¾ (JSON å­˜å‚¨ï¼Œä¾¿äºæ‰©å±•)
    features = Column(JSON, default={})
    # ç¤ºä¾‹ç»“æ„:
    # {
    #     "avg_speed_px_s": 125.5,
    #     "max_speed_px_s": 200.0,
    #     "path_length_px": 1500.0,
    #     "displacement_vec": [100, 50],
    #     "centroids": [[0.3, 0.5], [0.4, 0.6], ...]
    # }
    
    # å­˜å‚¨è·¯å¾„
    crops_prefix = Column(String(512))  # MinIO è·¯å¾„å‰ç¼€
    crop_count = Column(Integer, default=0)
    
    # ç´¢å¼•ä¼˜åŒ–
    __table_args__ = (
        Index("ix_track_video_local", "video_id", "local_track_id", unique=True),
    )
    
    video = relationship("Video", back_populates="tracks")


class SearchLog(Base):
    """æ£€ç´¢æ—¥å¿—è¡¨ï¼ˆç”¨äºåˆ†æå’Œå®¡è®¡ï¼‰"""
    __tablename__ = "search_logs"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    video_id = Column(String(36), ForeignKey("videos.id"))
    
    # æŸ¥è¯¢ä¿¡æ¯
    question = Column(String(1024), nullable=False)
    parsed_query = Column(JSON)  # Router è§£æåçš„ç»“æ„åŒ–æŸ¥è¯¢
    
    # ç»“æœä¿¡æ¯
    candidate_count = Column(Integer)
    match_count = Column(Integer)
    top_track_ids = Column(JSON)  # åŒ¹é…çš„ track_id åˆ—è¡¨
    
    # æ€§èƒ½æŒ‡æ ‡
    recall_latency_ms = Column(Integer)
    vlm_latency_ms = Column(Integer)
    total_latency_ms = Column(Integer)
    
    # æ¨¡å‹ä¿¡æ¯ï¼ˆA/B æµ‹è¯•ï¼‰
    model_variant = Column(String(64))
    
    # æ—¶é—´æˆ³
    created_at = Column(DateTime, server_default="now()")
```

### 6.3 å‘é‡å­˜å‚¨è®¾è®¡

```python
# adapters/vector/qdrant_adapter.py

from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance, VectorParams, PointStruct,
    Filter, FieldCondition, MatchValue
)


class QdrantVectorStore:
    """
    Qdrant å‘é‡å­˜å‚¨é€‚é…å™¨
    
    è®¾è®¡è¦ç‚¹ï¼š
    1. æ¯ä¸ªè§†é¢‘ä¸€ä¸ª Collectionï¼ˆéš”ç¦»æ€§ï¼‰
    2. Payload å­˜å‚¨è½»é‡å…ƒæ•°æ®ï¼ˆé¿å…å›æŸ¥æ•°æ®åº“ï¼‰
    3. æ”¯æŒæŒ‰ video_id è¿‡æ»¤
    """
    
    COLLECTION_PREFIX = "track_embeddings"
    VECTOR_DIM = 768  # SigLIP embedding ç»´åº¦
    
    def __init__(self, host: str = "localhost", port: int = 6333):
        self.client = QdrantClient(host=host, port=port)
    
    def ensure_collection(self, video_id: str):
        """ç¡®ä¿ Collection å­˜åœ¨"""
        collection_name = f"{self.COLLECTION_PREFIX}_{video_id}"
        
        collections = self.client.get_collections().collections
        if collection_name not in [c.name for c in collections]:
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(
                    size=self.VECTOR_DIM,
                    distance=Distance.COSINE
                )
            )
    
    def upsert_track_embedding(
        self,
        video_id: str,
        track_id: int,
        embedding: List[float],
        metadata: dict
    ):
        """æ’å…¥/æ›´æ–°è½¨è¿¹ embedding"""
        collection_name = f"{self.COLLECTION_PREFIX}_{video_id}"
        
        point = PointStruct(
            id=track_id,
            vector=embedding,
            payload={
                "video_id": video_id,
                "track_id": track_id,
                "start_seconds": metadata.get("start_seconds"),
                "end_seconds": metadata.get("end_seconds"),
                "duration_seconds": metadata.get("duration_seconds"),
            }
        )
        
        self.client.upsert(
            collection_name=collection_name,
            points=[point]
        )
    
    def search(
        self,
        video_id: str,
        query_vector: List[float],
        top_k: int = 50
    ) -> List[dict]:
        """å‘é‡æ£€ç´¢"""
        collection_name = f"{self.COLLECTION_PREFIX}_{video_id}"
        
        results = self.client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            limit=top_k,
        )
        
        return [
            {
                "track_id": hit.id,
                "score": hit.score,
                **hit.payload
            }
            for hit in results
        ]
```

---

## ç¬¬ä¸ƒç« ï¼šå‰ç«¯ä¸å¯è§†åŒ–è®¾è®¡

### 7.1 å‰ç«¯æŠ€æœ¯æ ˆé€‰å‹

| å±‚çº§ | æŠ€æœ¯ | é€‰å‹ç†ç”± |
|------|------|----------|
| æ¡†æ¶ | **Next.js 14** | SSR + App Router + API Routes |
| UI åº“ | **shadcn/ui** | å¯å®šåˆ¶ã€æ— ä¾èµ–é”å®šã€ç¾è§‚ |
| çŠ¶æ€ç®¡ç† | **Zustand** | è½»é‡ã€TypeScript å‹å¥½ |
| è§†é¢‘æ’­æ”¾ | **Video.js** | æˆç†Ÿç¨³å®šã€æ”¯æŒå„ç§æ ¼å¼ |
| å›¾è¡¨ | **Recharts** | å£°æ˜å¼ã€ä¸ React æ·±åº¦é›†æˆ |
| å®æ—¶é€šä¿¡ | **Socket.io** | ç´¢å¼•è¿›åº¦æ¨é€ |

### 7.2 æ ¸å¿ƒé¡µé¢è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          é¡µé¢æ¶æ„                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  /                              é¦–é¡µ/ä»ªè¡¨ç›˜                      â”‚
â”‚  â”œâ”€â”€ ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ                                                â”‚
â”‚  â”œâ”€â”€ æœ€è¿‘æ£€ç´¢å†å²                                                â”‚
â”‚  â””â”€â”€ å¿«é€Ÿæœç´¢å…¥å£                                                â”‚
â”‚                                                                  â”‚
â”‚  /videos                        è§†é¢‘ç®¡ç†                         â”‚
â”‚  â”œâ”€â”€ è§†é¢‘åˆ—è¡¨ï¼ˆåˆ†é¡µã€ç­›é€‰ï¼‰                                      â”‚
â”‚  â”œâ”€â”€ ä¸Šä¼ æ–°è§†é¢‘                                                  â”‚
â”‚  â””â”€â”€ ç´¢å¼•çŠ¶æ€ç›‘æ§                                                â”‚
â”‚                                                                  â”‚
â”‚  /videos/[id]                   è§†é¢‘è¯¦æƒ…                         â”‚
â”‚  â”œâ”€â”€ è§†é¢‘æ’­æ”¾å™¨                                                  â”‚
â”‚  â”œâ”€â”€ è½¨è¿¹æ—¶é—´çº¿                                                  â”‚
â”‚  â”œâ”€â”€ è½¨è¿¹ç¼©ç•¥å›¾ç½‘æ ¼                                              â”‚
â”‚  â””â”€â”€ æœç´¢é¢æ¿                                                    â”‚
â”‚                                                                  â”‚
â”‚  /videos/[id]/search            æ£€ç´¢ç»“æœ                         â”‚
â”‚  â”œâ”€â”€ æŸ¥è¯¢è¾“å…¥                                                    â”‚
â”‚  â”œâ”€â”€ åŒ¹é…ç»“æœåˆ—è¡¨                                                â”‚
â”‚  â”œâ”€â”€ é«˜äº®è§†é¢‘é¢„è§ˆ                                                â”‚
â”‚  â””â”€â”€ å¯¼å‡ºåŠŸèƒ½                                                    â”‚
â”‚                                                                  â”‚
â”‚  /analytics                     åˆ†æé¢æ¿                         â”‚
â”‚  â”œâ”€â”€ æ£€ç´¢æ€§èƒ½ç»Ÿè®¡                                                â”‚
â”‚  â”œâ”€â”€ æ¨¡å‹æ•ˆæœå¯¹æ¯”ï¼ˆA/B æµ‹è¯•ï¼‰                                    â”‚
â”‚  â””â”€â”€ ä½¿ç”¨é‡è¶‹åŠ¿                                                  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.3 æ ¸å¿ƒç»„ä»¶è®¾è®¡

```tsx
// components/VideoPlayer/index.tsx
interface VideoPlayerProps {
  videoUrl: string;
  tracks: Track[];
  highlightedTrackIds: number[];
  onTimeUpdate: (time: number) => void;
}

/**
 * å¢å¼ºè§†é¢‘æ’­æ”¾å™¨
 * 
 * åŠŸèƒ½ï¼š
 * 1. å åŠ è½¨è¿¹è¾¹ç•Œæ¡†
 * 2. æ—¶é—´è½´ä¸Šæ˜¾ç¤ºè½¨è¿¹åŒºé—´
 * 3. ç‚¹å‡»è½¨è¿¹è·³è½¬åˆ°å¯¹åº”æ—¶é—´
 * 4. é«˜äº®åŒ¹é…çš„è½¨è¿¹
 */
export function VideoPlayer({
  videoUrl,
  tracks,
  highlightedTrackIds,
  onTimeUpdate,
}: VideoPlayerProps) {
  // å®ç°...
}

// components/TrackTimeline/index.tsx
interface TrackTimelineProps {
  tracks: Track[];
  duration: number;
  highlightedIds: number[];
  onTrackClick: (trackId: number) => void;
}

/**
 * è½¨è¿¹æ—¶é—´çº¿ç»„ä»¶
 * 
 * è®¾è®¡ï¼š
 * - æ¯æ¡è½¨è¿¹ä¸€è¡Œï¼Œæ˜¾ç¤ºå…¶åœ¨è§†é¢‘ä¸­çš„æ—¶é—´è·¨åº¦
 * - é«˜äº®åŒ¹é…çš„è½¨è¿¹
 * - æ”¯æŒç¼©æ”¾å’Œå¹³ç§»
 * - æ‚¬åœæ˜¾ç¤ºè½¨è¿¹è¯¦æƒ…
 */
export function TrackTimeline({ ... }) {
  // å®ç°...
}

// components/SearchPanel/index.tsx
interface SearchPanelProps {
  videoId: string;
  onSearchComplete: (results: SearchResult[]) => void;
}

/**
 * æœç´¢é¢æ¿ç»„ä»¶
 * 
 * åŠŸèƒ½ï¼š
 * 1. è‡ªç„¶è¯­è¨€è¾“å…¥
 * 2. é«˜çº§é€‰é¡¹ï¼ˆå¬å›æ•°é‡ã€ç¡¬è§„åˆ™ï¼‰
 * 3. æœç´¢å†å²
 * 4. å®æ—¶åŠ è½½çŠ¶æ€
 */
export function SearchPanel({ ... }) {
  // å®ç°...
}
```

### 7.4 å®æ—¶è¿›åº¦æ¨é€

```python
# api/routes/websocket.py
from fastapi import WebSocket, WebSocketDisconnect

class ConnectionManager:
    """WebSocket è¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.active_connections: Dict[str, List[WebSocket]] = {}
    
    async def connect(self, websocket: WebSocket, video_id: str):
        await websocket.accept()
        if video_id not in self.active_connections:
            self.active_connections[video_id] = []
        self.active_connections[video_id].append(websocket)
    
    async def broadcast_progress(self, video_id: str, progress: dict):
        """å¹¿æ’­ç´¢å¼•è¿›åº¦"""
        if video_id in self.active_connections:
            for connection in self.active_connections[video_id]:
                await connection.send_json({
                    "type": "index_progress",
                    "data": progress
                })

manager = ConnectionManager()

@router.websocket("/ws/videos/{video_id}/progress")
async def video_progress_ws(websocket: WebSocket, video_id: str):
    await manager.connect(websocket, video_id)
    try:
        while True:
            await websocket.receive_text()  # ä¿æŒè¿æ¥
    except WebSocketDisconnect:
        manager.disconnect(websocket, video_id)
```

```typescript
// hooks/useIndexProgress.ts
export function useIndexProgress(videoId: string) {
  const [progress, setProgress] = useState<IndexProgress | null>(null);
  
  useEffect(() => {
    const ws = new WebSocket(`ws://localhost:8000/ws/videos/${videoId}/progress`);
    
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.type === 'index_progress') {
        setProgress(data.data);
      }
    };
    
    return () => ws.close();
  }, [videoId]);
  
  return progress;
}
```

---

## ç¬¬å…«ç« ï¼šå¯è§‚æµ‹æ€§ä¸è¿ç»´

### 8.1 ç»“æ„åŒ–æ—¥å¿—

```python
# infrastructure/logging/structured_logger.py

import structlog
from datetime import datetime


def configure_logging():
    """é…ç½®ç»“æ„åŒ–æ—¥å¿—"""
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        wrapper_class=structlog.stdlib.BoundLogger,
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )


logger = structlog.get_logger()

# ä½¿ç”¨ç¤ºä¾‹
logger.info(
    "search_completed",
    video_id=video_id,
    question=question,
    model_variant="vllm",
    candidate_count=36,
    match_count=5,
    recall_latency_ms=150,
    vlm_latency_ms=12500,
    total_latency_ms=12800,
)
```

### 8.2 Prometheus æŒ‡æ ‡

```python
# infrastructure/metrics/prometheus.py

from prometheus_client import Counter, Histogram, Gauge


# ä¸šåŠ¡æŒ‡æ ‡
SEARCH_TOTAL = Counter(
    "edge_detective_search_total",
    "Total number of search requests",
    ["video_id", "model_variant"]
)

SEARCH_LATENCY = Histogram(
    "edge_detective_search_latency_seconds",
    "Search request latency",
    ["stage"],  # recall, vlm, total
    buckets=[0.1, 0.5, 1, 2, 5, 10, 30, 60, 120]
)

MATCH_COUNT = Histogram(
    "edge_detective_match_count",
    "Number of matches per search",
    buckets=[0, 1, 2, 5, 10, 20, 50]
)

# æŠ€æœ¯æŒ‡æ ‡
GPU_UTILIZATION = Gauge(
    "edge_detective_gpu_utilization_percent",
    "GPU utilization percentage"
)

VLM_QUEUE_LENGTH = Gauge(
    "edge_detective_vlm_queue_length",
    "Number of pending VLM requests"
)

VLM_TOKENS_PER_SECOND = Gauge(
    "edge_detective_vlm_tokens_per_second",
    "VLM generation throughput"
)
```

### 8.3 å¥åº·æ£€æŸ¥

```python
# api/routes/health.py

from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

router = APIRouter()


@router.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """ç»¼åˆå¥åº·æ£€æŸ¥"""
    checks = {
        "database": await check_database(db),
        "redis": await check_redis(),
        "qdrant": await check_qdrant(),
        "vllm": await check_vllm(),
        "minio": await check_minio(),
        "disk_space": check_disk_space(),
    }
    
    status = "healthy" if all(checks.values()) else "degraded"
    
    return {
        "status": status,
        "checks": checks,
        "timestamp": datetime.utcnow().isoformat()
    }


@router.get("/health/ready")
async def readiness_check():
    """å°±ç»ªæ£€æŸ¥ï¼ˆK8s readinessProbeï¼‰"""
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¥æ”¶æµé‡
    return {"ready": True}


@router.get("/health/live")
async def liveness_check():
    """å­˜æ´»æ£€æŸ¥ï¼ˆK8s livenessProbeï¼‰"""
    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
    return {"alive": True}
```

### 8.4 å‘Šè­¦è§„åˆ™

```yaml
# deploy/prometheus/alerts.yml

groups:
  - name: edge-detective-alerts
    rules:
      # é«˜å»¶è¿Ÿå‘Šè­¦
      - alert: HighSearchLatency
        expr: histogram_quantile(0.95, rate(edge_detective_search_latency_seconds_bucket{stage="total"}[5m])) > 30
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Search latency P95 exceeds 30s"
          description: "{{ $value }}s"
      
      # VLM æœåŠ¡ä¸å¯ç”¨
      - alert: VLMServiceDown
        expr: up{job="vllm"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "vLLM service is down"
      
      # GPU åˆ©ç”¨ç‡ä½
      - alert: LowGPUUtilization
        expr: edge_detective_gpu_utilization_percent < 30
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "GPU utilization below 30%"
          description: "Consider scaling down or investigating batch efficiency"
      
      # ç£ç›˜ç©ºé—´ä¸è¶³
      - alert: LowDiskSpace
        expr: node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} < 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space below 10%"
```

---

## ç¬¬ä¹ç« ï¼šæ¼”è¿›è·¯çº¿å›¾

### 9.1 Phase 1: MVP (2-3 å‘¨)

**ç›®æ ‡**: ä» CLI è„šæœ¬å‡çº§ä¸ºå¯è¢«å¤–éƒ¨ç³»ç»Ÿè°ƒç”¨çš„æœåŠ¡

```
Week 1:
â”œâ”€â”€ Day 1-2: FastAPI éª¨æ¶ + å¥åº·æ£€æŸ¥
â”œâ”€â”€ Day 3-4: vLLM éƒ¨ç½² + å®¢æˆ·ç«¯é€‚é…å™¨
â””â”€â”€ Day 5: ç«¯åˆ°ç«¯æµ‹è¯•

Week 2:
â”œâ”€â”€ Day 1-2: PostgreSQL æ¨¡å‹ + Alembic è¿ç§»
â”œâ”€â”€ Day 3-4: Celery å¼‚æ­¥ä»»åŠ¡
â””â”€â”€ Day 5: Docker Compose æ•´åˆ

Week 3:
â”œâ”€â”€ Day 1-2: ç»“æ„åŒ–æ—¥å¿— + åŸºç¡€ç›‘æ§
â”œâ”€â”€ Day 3: API æ–‡æ¡£å®Œå–„
â””â”€â”€ Day 4-5: å‹åŠ›æµ‹è¯• + æ€§èƒ½åŸºå‡†
```

**äº¤ä»˜ç‰©æ£€æŸ¥æ¸…å•**:
- [ ] FastAPI æœåŠ¡å¯å¯åŠ¨
- [ ] vLLM æœåŠ¡ç‹¬ç«‹è¿è¡Œ
- [ ] POST /api/v1/search å¯è¿”å›ç»“æœ
- [ ] ç´¢å¼•ä»»åŠ¡å¯åå°æ‰§è¡Œ
- [ ] Prometheus æŒ‡æ ‡å¯é‡‡é›†
- [ ] Docker Compose ä¸€é”®å¯åŠ¨

### 9.2 Phase 2: ç”Ÿäº§å¯ç”¨ (3-4 å‘¨)

**ç›®æ ‡**: æ€§èƒ½ä¼˜åŒ– + ç¨³å®šéƒ¨ç½²

```
Week 4:
â”œâ”€â”€ Qdrant å‘é‡åº“é›†æˆ
â”œâ”€â”€ RecallEngine é‡æ„ï¼ˆä½¿ç”¨å‘é‡æ£€ç´¢ï¼‰
â””â”€â”€ MinIO å¯¹è±¡å­˜å‚¨

Week 5:
â”œâ”€â”€ é‡åŒ–æ¨¡å‹é€‚é…å™¨
â”œâ”€â”€ ModelRegistry å®ç°
â””â”€â”€ A/B æµ‹è¯•æ¡†æ¶

Week 6:
â”œâ”€â”€ å‰ç«¯éª¨æ¶ (Next.js)
â”œâ”€â”€ è§†é¢‘æ’­æ”¾å™¨ç»„ä»¶
â””â”€â”€ æœç´¢é¢æ¿

Week 7:
â”œâ”€â”€ WebSocket è¿›åº¦æ¨é€
â”œâ”€â”€ å®Œæ•´ E2E æµ‹è¯•
â””â”€â”€ æ€§èƒ½ä¼˜åŒ–ï¼ˆç›®æ ‡ï¼šP95 < 15sï¼‰
```

**äº¤ä»˜ç‰©æ£€æŸ¥æ¸…å•**:
- [ ] æ£€ç´¢ P95 å»¶è¿Ÿ < 15s
- [ ] æ”¯æŒ FP16 / INT4 æ¨¡å‹åˆ‡æ¢
- [ ] å‰ç«¯å¯å±•ç¤ºæ£€ç´¢ç»“æœ
- [ ] ç´¢å¼•è¿›åº¦å®æ—¶æ¨é€
- [ ] æ”¯æŒ 10 å¹¶å‘ç”¨æˆ·

### 9.3 Phase 3: è§„æ¨¡åŒ– (4-6 å‘¨)

**ç›®æ ‡**: æ”¯æŒå®æ—¶æµã€å¤šæ‘„åƒå¤´ã€é«˜å¹¶å‘

```
Week 8-9:
â”œâ”€â”€ RTSP æµå¤„ç†å™¨
â”œâ”€â”€ å®æ—¶ç´¢å¼•æ›´æ–°
â””â”€â”€ å¤šæ‘„åƒå¤´ç®¡ç† API

Week 10-11:
â”œâ”€â”€ Re-ID è·¨é•œè¿½è¸ª
â”œâ”€â”€ äº‹ä»¶å‘Šè­¦ç³»ç»Ÿ
â””â”€â”€ Kubernetes éƒ¨ç½²é…ç½®

Week 12-13:
â”œâ”€â”€ HPA è‡ªåŠ¨æ‰©ç¼©å®¹
â”œâ”€â”€ é“¾è·¯è¿½è¸ª (OpenTelemetry)
â””â”€â”€ è¿ç»´ Runbook
```

**äº¤ä»˜ç‰©æ£€æŸ¥æ¸…å•**:
- [ ] æ”¯æŒ RTSP å®æ—¶æµ
- [ ] æ”¯æŒ 10+ æ‘„åƒå¤´å¹¶å‘
- [ ] å®æ—¶å»¶è¿Ÿ < 5s
- [ ] K8s éƒ¨ç½²æˆåŠŸ
- [ ] å®Œæ•´è¿ç»´æ–‡æ¡£

### 9.4 é‡Œç¨‹ç¢‘éªŒæ”¶æ ‡å‡†

| é˜¶æ®µ | å…³é”®æŒ‡æ ‡ | éªŒæ”¶æ ‡å‡† |
|------|----------|----------|
| Phase 1 | API å¯ç”¨ | HTTP å®Œæˆç´¢å¼•+æ£€ç´¢ |
| Phase 2 | æ€§èƒ½è¾¾æ ‡ | æ£€ç´¢ P95 < 15s |
| Phase 3 | è§„æ¨¡åŒ– | 10+ æ‘„åƒå¤´ï¼Œå®æ—¶å»¶è¿Ÿ < 5s |

---

## é™„å½•ï¼šå…³é”®ä»£ç å®ç°

### A.1 åº”ç”¨å±‚ï¼šæ£€ç´¢ç”¨ä¾‹

```python
# application/use_cases/search_tracks.py

from dataclasses import dataclass
from typing import List, Optional

from domain.entities.evidence import EvidencePackage
from domain.services.hard_rule_engine import HardRuleEngine
from ports.inference_port import InferencePort
from ports.vector_store_port import VectorStorePort
from adapters.inference.model_registry import ModelRegistry


@dataclass
class SearchRequest:
    video_id: str
    question: str
    top_k: int = 5
    recall_limit: int = 50
    model_priority: str = "high_accuracy"


@dataclass
class SearchResult:
    track_id: int
    start_seconds: float
    end_seconds: float
    score: float
    reason: str


@dataclass
class SearchResponse:
    video_id: str
    question: str
    results: List[SearchResult]
    latency_ms: int
    model_variant: str


class SearchTracksUseCase:
    """
    è½¨è¿¹æ£€ç´¢ç”¨ä¾‹
    
    ç¼–æ’æµç¨‹ï¼š
    1. Router è§£æé—®é¢˜ â†’ ExecutionPlan
    2. å‘é‡å¬å› â†’ å€™é€‰è½¨è¿¹
    3. ç¡¬è§„åˆ™è¿‡æ»¤ â†’ ç¼©å°èŒƒå›´
    4. VLM éªŒè¯ â†’ æœ€ç»ˆåŒ¹é…
    5. æ’åºè¿”å› â†’ Top-K ç»“æœ
    """
    
    def __init__(
        self,
        model_registry: ModelRegistry,
        vector_store: VectorStorePort,
        hard_rule_engine: HardRuleEngine,
        router: QueryRouter,
    ):
        self.model_registry = model_registry
        self.vector_store = vector_store
        self.hard_rule_engine = hard_rule_engine
        self.router = router
    
    async def execute(self, request: SearchRequest) -> SearchResponse:
        import time
        start_time = time.time()
        
        # Step 1: è§£æé—®é¢˜
        plan = self.router.build_plan(request.question)
        
        # Step 2: å‘é‡å¬å›
        query_embedding = self._encode_query(plan.description, plan.visual_tags)
        candidates = await self.vector_store.search(
            video_id=request.video_id,
            query_vector=query_embedding,
            top_k=request.recall_limit,
        )
        
        # Step 3: åŠ è½½è¯æ®åŒ…
        evidence_packages = await self._load_evidence_packages(
            request.video_id, [c["track_id"] for c in candidates]
        )
        
        # Step 4: ç¡¬è§„åˆ™è¿‡æ»¤
        filtered = self.hard_rule_engine.apply_constraints(evidence_packages, plan)
        
        # Step 5: VLM éªŒè¯
        adapter = self.model_registry.get_adapter(
            InferencePriority(request.model_priority)
        )
        vlm_results = await adapter.verify_batch(
            packages=filtered,
            question=request.question,
            plan_context=plan.to_context_string(),
        )
        
        # Step 6: ç­›é€‰åŒ¹é…ç»“æœ
        matches = [
            SearchResult(
                track_id=pkg.track_id,
                start_seconds=pkg.start_time_seconds,
                end_seconds=pkg.end_time_seconds,
                score=result.confidence,
                reason=result.reason,
            )
            for pkg, result in zip(filtered, vlm_results)
            if result.is_match
        ]
        
        # Step 7: æ’åºå– Top-K
        matches.sort(key=lambda x: x.score, reverse=True)
        top_matches = matches[:request.top_k]
        
        elapsed_ms = int((time.time() - start_time) * 1000)
        
        return SearchResponse(
            video_id=request.video_id,
            question=request.question,
            results=top_matches,
            latency_ms=elapsed_ms,
            model_variant=adapter.__class__.__name__,
        )
```

### A.2 é…ç½®ç®¡ç†

```python
# infrastructure/config/app_config.py

from pydantic_settings import BaseSettings
from typing import Optional


class AppConfig(BaseSettings):
    """åº”ç”¨é…ç½®ï¼ˆä¸šåŠ¡å±‚ï¼‰"""
    
    # æœåŠ¡é…ç½®
    service_name: str = "edge-detective"
    debug: bool = False
    
    # æ•°æ®åº“
    database_url: str = "postgresql://user:pass@localhost:5432/edge_detective"
    
    # Redis
    redis_url: str = "redis://localhost:6379/0"
    
    # å‘é‡åº“
    qdrant_host: str = "localhost"
    qdrant_port: int = 6333
    
    # å¯¹è±¡å­˜å‚¨
    minio_endpoint: str = "localhost:9000"
    minio_access_key: str = "minioadmin"
    minio_secret_key: str = "minioadmin"
    minio_bucket: str = "edge-detective"
    
    # æ¨ç†æœåŠ¡
    vllm_enabled: bool = True
    vllm_endpoint: str = "http://localhost:8000/v1"
    vllm_model_name: str = "Qwen/Qwen3-VL-4B-Instruct"
    
    quantized_enabled: bool = False
    quantized_model_path: str = "models/qwen2-vl-7b-awq.gguf"
    
    cloud_api_enabled: bool = False
    cloud_api_key: Optional[str] = None
    
    # ä¸šåŠ¡å‚æ•°
    default_top_k: int = 5
    default_recall_limit: int = 50
    max_images_per_request: int = 5
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


class InfraConfig(BaseSettings):
    """åŸºç¡€è®¾æ–½é…ç½®ï¼ˆè¿ç»´å±‚ï¼‰"""
    
    # GPU é…ç½®
    gpu_memory_utilization: float = 0.90
    tensor_parallel_size: int = 1
    
    # æ£€æµ‹æ¨¡å‹
    yolo_model: str = "yolo11n.pt"
    yolo_device: str = "cuda"
    yolo_conf: float = 0.5
    
    # è¿½è¸ªå™¨
    tracker_type: str = "bytetrack"
    min_track_length: int = 15
    sample_interval: int = 5
    
    class Config:
        env_file = ".env.infra"
```

---

## ç»“è¯­

æœ¬æ–‡æ¡£ä¸ä»…ä»…æ˜¯ä¸€ä»½æŠ€æœ¯å‡çº§æŒ‡å—ï¼Œæ›´æ˜¯ä¸€ä»½**ç³»ç»Ÿå·¥ç¨‹çš„è®¾è®¡å“²å­¦å®£è¨€**ã€‚

é€šè¿‡å¼•å…¥ **å¼‚æ„è®¡ç®—ç‰©ç†éš”ç¦»**ï¼Œæˆ‘ä»¬è§£é™¤äº† Python ä¸šåŠ¡é€»è¾‘ä¸ GPU æ¨ç†çš„å¼ºè€¦åˆï¼›
é€šè¿‡ **ç«¯å£é€‚é…å™¨æ¨¡å¼**ï¼Œæˆ‘ä»¬ä¸º vLLMã€é‡åŒ–æ¨¡å‹ã€äº‘ç«¯ API é¢„ç•™äº†æ ‡å‡†æ’æ§½ï¼›
é€šè¿‡ **åè…è´¥å±‚**ï¼Œæˆ‘ä»¬éš”ç¦»äº† VLM è¾“å‡ºçš„ä¸ç¡®å®šæ€§ï¼›
é€šè¿‡ **CQRS æ€æƒ³**ï¼Œæˆ‘ä»¬å¹³è¡¡äº†é«˜ååç´¢å¼•ä¸ä½å»¶è¿Ÿæ£€ç´¢çš„çŸ›ç›¾ã€‚

è¿™æ˜¯ä¸€å¥—èƒ½å¤Ÿæ”¯æ’‘ Edge-Detective ä»å®éªŒå®¤åŸå‹èµ°å‘å¤§è§„æ¨¡å·¥ä¸šéƒ¨ç½²çš„åšå®åŸºçŸ³ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-12-05  
**ä½œè€…**: AI Assistant  
**å®¡é˜…**: Pending

