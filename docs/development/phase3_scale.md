# ğŸš€ Phase 3: è§„æ¨¡åŒ– å¼€å‘è®¡åˆ’

> **ç›®æ ‡**: æ”¯æŒå®æ—¶æµã€å¤šæ‘„åƒå¤´ã€é«˜å¹¶å‘ã€K8s éƒ¨ç½²  
> **å‘¨æœŸ**: 4-6 å‘¨  
> **å‰ç½®æ¡ä»¶**: Phase 2 å®Œæˆ

---

## ç›®å½•

1. [Week 8-9: å®æ—¶æµå¤„ç†](#week-8-9-å®æ—¶æµå¤„ç†)
2. [Week 10-11: Re-ID + äº‹ä»¶å‘Šè­¦](#week-10-11-re-id--äº‹ä»¶å‘Šè­¦)
3. [Week 12-13: Kubernetes éƒ¨ç½²](#week-12-13-kubernetes-éƒ¨ç½²)
4. [æœ€ç»ˆç›®å½•ç»“æ„](#æœ€ç»ˆç›®å½•ç»“æ„)
5. [å®Œæ•´åˆ é™¤æ¸…å•](#å®Œæ•´åˆ é™¤æ¸…å•)
6. [éªŒæ”¶æ ‡å‡†](#éªŒæ”¶æ ‡å‡†)

---

## Week 8-9: å®æ—¶æµå¤„ç†

### å®æ—¶æµå¤„ç†å™¨

**`src/adapters/streaming/rtsp_processor.py`**
```python
"""RTSP æµå¤„ç†å™¨"""
from __future__ import annotations

import cv2
import time
from collections import deque
from dataclasses import dataclass, field
from typing import Dict, Callable, Optional
from threading import Thread, Event

from ultralytics import YOLO
from boxmot import create_tracker

from core.perception import TrackRecord


@dataclass
class StreamConfig:
    """æµé…ç½®"""
    url: str
    camera_id: str
    buffer_size: int = 300  # 10s @ 30fps
    detection_interval: int = 1  # æ¯å¸§æ£€æµ‹


class RtspStreamProcessor:
    """
    RTSP å®æ—¶æµå¤„ç†å™¨
    
    åŠŸèƒ½ï¼š
    - å®æ—¶è¯»å– RTSP/RTMP æµ
    - æŒç»­æ£€æµ‹å’Œè¿½è¸ª
    - è½¨è¿¹å®Œæˆæ—¶å›è°ƒ
    """
    
    def __init__(
        self,
        config: StreamConfig,
        yolo_model: str = "yolo11n.pt",
        tracker_type: str = "bytetrack",
    ):
        self.config = config
        self.cap = cv2.VideoCapture(config.url)
        self.yolo = YOLO(yolo_model)
        self.tracker = create_tracker(
            tracker_type=tracker_type,
            tracker_config=None,
            reid_weights=None,
            device="cuda",
            half=False,
            per_class=True,
        )
        
        self.frame_buffer = deque(maxlen=config.buffer_size)
        self.active_tracks: Dict[int, TrackRecord] = {}
        self.frame_idx = 0
        self._stop_event = Event()
        self._thread: Optional[Thread] = None
    
    def start(self, on_track_complete: Callable[[TrackRecord], None]):
        """å¯åŠ¨æµå¤„ç†"""
        self._stop_event.clear()
        self._thread = Thread(
            target=self._run_loop,
            args=(on_track_complete,),
            daemon=True
        )
        self._thread.start()
    
    def stop(self):
        """åœæ­¢æµå¤„ç†"""
        self._stop_event.set()
        if self._thread:
            self._thread.join(timeout=5)
        self.cap.release()
    
    def _run_loop(self, on_track_complete: Callable):
        """ä¸»å¾ªç¯"""
        while not self._stop_event.is_set():
            ret, frame = self.cap.read()
            if not ret:
                time.sleep(0.01)
                continue
            
            self.frame_idx += 1
            self.frame_buffer.append((self.frame_idx, frame))
            
            # æ£€æµ‹
            if self.frame_idx % self.config.detection_interval == 0:
                self._process_frame(frame, on_track_complete)
    
    def _process_frame(self, frame, on_track_complete: Callable):
        """å¤„ç†å•å¸§"""
        results = self.yolo.predict(
            source=frame,
            device="cuda",
            conf=0.5,
            verbose=False,
            classes=[0],
        )[0]
        
        detections = []
        if results.boxes is not None:
            for i in range(len(results.boxes)):
                x1, y1, x2, y2 = results.boxes.xyxy[i].cpu().numpy()
                conf = float(results.boxes.conf[i])
                detections.append([x1, y1, x2, y2, conf, 0])
        
        if not detections:
            return
        
        import numpy as np
        tracks = self.tracker.update(np.array(detections), frame)
        
        active_ids = set()
        for track in tracks:
            x1, y1, x2, y2 = map(int, track[:4])
            tid = int(track[4])
            active_ids.add(tid)
            
            if tid not in self.active_tracks:
                self.active_tracks[tid] = TrackRecord(
                    track_id=tid, frames=[], bboxes=[], crops=[]
                )
            
            record = self.active_tracks[tid]
            record.frames.append(self.frame_idx)
            record.bboxes.append((x1, y1, x2, y2))
        
        # æ£€æŸ¥å·²ç»“æŸçš„è½¨è¿¹
        for tid in list(self.active_tracks.keys()):
            if tid not in active_ids:
                record = self.active_tracks[tid]
                if self.frame_idx - record.frames[-1] > 30:  # 1ç§’æœªå‡ºç°
                    on_track_complete(record)
                    del self.active_tracks[tid]
```

### å¤šæ‘„åƒå¤´ç®¡ç†

**`src/adapters/streaming/camera_manager.py`**
```python
"""å¤šæ‘„åƒå¤´ç®¡ç†å™¨"""
from typing import Dict
from concurrent.futures import ThreadPoolExecutor

from adapters.streaming.rtsp_processor import RtspStreamProcessor, StreamConfig
from core.perception import TrackRecord


class CameraManager:
    """
    å¤šæ‘„åƒå¤´ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    - ç®¡ç†å¤šä¸ªæ‘„åƒå¤´æµ
    - åŠ¨æ€æ·»åŠ /ç§»é™¤æ‘„åƒå¤´
    - ç»Ÿä¸€çš„è½¨è¿¹å›è°ƒ
    """
    
    def __init__(self, max_cameras: int = 16):
        self.processors: Dict[str, RtspStreamProcessor] = {}
        self.executor = ThreadPoolExecutor(max_workers=max_cameras)
    
    def add_camera(
        self,
        camera_id: str,
        stream_url: str,
        on_track_complete=None
    ):
        """æ·»åŠ æ‘„åƒå¤´"""
        if camera_id in self.processors:
            raise ValueError(f"Camera {camera_id} already exists")
        
        config = StreamConfig(url=stream_url, camera_id=camera_id)
        processor = RtspStreamProcessor(config)
        self.processors[camera_id] = processor
        
        if on_track_complete:
            processor.start(on_track_complete)
    
    def remove_camera(self, camera_id: str):
        """ç§»é™¤æ‘„åƒå¤´"""
        if camera_id in self.processors:
            self.processors[camera_id].stop()
            del self.processors[camera_id]
    
    def list_cameras(self) -> list:
        """åˆ—å‡ºæ‰€æœ‰æ‘„åƒå¤´"""
        return list(self.processors.keys())
    
    def stop_all(self):
        """åœæ­¢æ‰€æœ‰æ‘„åƒå¤´"""
        for proc in self.processors.values():
            proc.stop()
        self.processors.clear()
        self.executor.shutdown(wait=True)
```

### å®æ—¶ç´¢å¼•æ›´æ–°

**`src/application/use_cases/realtime_index.py`**
```python
"""å®æ—¶ç´¢å¼•ç”¨ä¾‹"""
from core.perception import TrackRecord
from adapters.vector.qdrant_adapter import QdrantAdapter


class RealtimeIndexer:
    """å®æ—¶ç´¢å¼•å™¨"""
    
    def __init__(
        self,
        vector_store: QdrantAdapter,
        siglip_client,
    ):
        self.vector_store = vector_store
        self.siglip = siglip_client
    
    async def on_track_complete(
        self,
        camera_id: str,
        record: TrackRecord
    ):
        """è½¨è¿¹å®Œæˆæ—¶è§¦å‘ç´¢å¼•"""
        # 1. è®¡ç®—ç‰¹å¾
        # 2. ç”Ÿæˆ embedding
        # 3. å†™å…¥å‘é‡åº“
        # 4. å†™å…¥å…ƒæ•°æ®åº“
        pass
```

---

## Week 10-11: Re-ID + äº‹ä»¶å‘Šè­¦

### Re-ID è·¨é•œè¿½è¸ª

**`src/adapters/reid/osnet_adapter.py`**
```python
"""OSNet Re-ID é€‚é…å™¨"""
import torch
import numpy as np
from PIL import Image
from typing import List, Tuple


class OSNetReIDAdapter:
    """
    OSNet Re-ID æ¨¡å‹é€‚é…å™¨
    
    ç”¨äºè·¨æ‘„åƒå¤´äººå‘˜é‡è¯†åˆ«
    """
    
    def __init__(self, model_name: str = "osnet_x1_0"):
        import torchreid
        self.model = torchreid.models.build_model(
            name=model_name,
            num_classes=1000,
            pretrained=True
        )
        self.model.eval()
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model.to(self.device)
    
    def extract_feature(self, images: List[Image.Image]) -> np.ndarray:
        """æå– Re-ID ç‰¹å¾"""
        # é¢„å¤„ç†
        import torchvision.transforms as T
        transform = T.Compose([
            T.Resize((256, 128)),
            T.ToTensor(),
            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        tensors = [transform(img) for img in images]
        batch = torch.stack(tensors).to(self.device)
        
        with torch.no_grad():
            features = self.model(batch)
        
        return features.cpu().numpy().mean(axis=0)
    
    def match(
        self,
        query_feature: np.ndarray,
        gallery_features: List[np.ndarray],
        threshold: float = 0.7
    ) -> List[Tuple[int, float]]:
        """åŒ¹é…"""
        matches = []
        for i, feat in enumerate(gallery_features):
            similarity = np.dot(query_feature, feat) / (
                np.linalg.norm(query_feature) * np.linalg.norm(feat)
            )
            if similarity > threshold:
                matches.append((i, float(similarity)))
        return sorted(matches, key=lambda x: x[1], reverse=True)
```

### äº‹ä»¶å‘Šè­¦ç³»ç»Ÿ

**`src/adapters/events/alert_system.py`**
```python
"""äº‹ä»¶å‘Šè­¦ç³»ç»Ÿ"""
from dataclasses import dataclass
from typing import List, Optional
from datetime import datetime
import aiohttp


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    name: str
    description: str
    condition: str  # è§„åˆ™è¡¨è¾¾å¼
    severity: str  # info, warning, critical
    webhook_url: Optional[str] = None


@dataclass
class Alert:
    """å‘Šè­¦"""
    rule_name: str
    camera_id: str
    track_id: int
    timestamp: datetime
    description: str
    thumbnail_url: Optional[str] = None


class AlertSystem:
    """
    äº‹ä»¶å‘Šè­¦ç³»ç»Ÿ
    
    åŠŸèƒ½ï¼š
    - è§„åˆ™ç®¡ç†
    - å®æ—¶æ£€æµ‹
    - Webhook é€šçŸ¥
    """
    
    def __init__(self, rules: List[AlertRule]):
        self.rules = {r.name: r for r in rules}
    
    async def check(self, camera_id: str, track, features) -> List[Alert]:
        """æ£€æŸ¥æ˜¯å¦è§¦å‘å‘Šè­¦"""
        alerts = []
        for rule in self.rules.values():
            if self._evaluate_rule(rule, track, features):
                alert = Alert(
                    rule_name=rule.name,
                    camera_id=camera_id,
                    track_id=track.track_id,
                    timestamp=datetime.utcnow(),
                    description=rule.description,
                )
                alerts.append(alert)
                
                if rule.webhook_url:
                    await self._send_webhook(rule.webhook_url, alert)
        
        return alerts
    
    def _evaluate_rule(self, rule: AlertRule, track, features) -> bool:
        """è¯„ä¼°è§„åˆ™ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰"""
        # TODO: å®ç°è§„åˆ™å¼•æ“
        return False
    
    async def _send_webhook(self, url: str, alert: Alert):
        """å‘é€ Webhook"""
        async with aiohttp.ClientSession() as session:
            await session.post(url, json={
                "rule": alert.rule_name,
                "camera": alert.camera_id,
                "track_id": alert.track_id,
                "timestamp": alert.timestamp.isoformat(),
                "description": alert.description,
            })
```

---

## Week 12-13: Kubernetes éƒ¨ç½²

### K8s é…ç½®æ–‡ä»¶

**`deploy/k8s/api-deployment.yaml`**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: edge-detective-api
  labels:
    app: edge-detective
    component: api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: edge-detective
      component: api
  template:
    metadata:
      labels:
        app: edge-detective
        component: api
    spec:
      containers:
      - name: api
        image: edge-detective:latest
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: edge-detective-secrets
              key: database-url
        - name: VLLM_ENDPOINT
          value: "http://vllm-service:8000/v1"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: edge-detective-api
spec:
  selector:
    app: edge-detective
    component: api
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP
```

**`deploy/k8s/vllm-deployment.yaml`**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-server
  labels:
    app: edge-detective
    component: vllm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: edge-detective
      component: vllm
  template:
    metadata:
      labels:
        app: edge-detective
        component: vllm
    spec:
      containers:
      - name: vllm
        image: vllm/vllm-openai:latest
        args:
        - "--model"
        - "Qwen/Qwen3-VL-4B-Instruct"
        - "--trust-remote-code"
        - "--host"
        - "0.0.0.0"
        - "--port"
        - "8000"
        - "--gpu-memory-utilization"
        - "0.90"
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "16Gi"
            nvidia.com/gpu: 1
          limits:
            memory: "24Gi"
            nvidia.com/gpu: 1
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-service
spec:
  selector:
    app: edge-detective
    component: vllm
  ports:
  - port: 8000
    targetPort: 8000
  type: ClusterIP
```

**`deploy/k8s/hpa.yaml`**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: edge-detective-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: edge-detective-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

---

## æœ€ç»ˆç›®å½•ç»“æ„

> å®Œæ•´é‡æ„åçš„ç›®å½•ç»“æ„ï¼Œä¸ `final_upgrade_blueprint.md` ä¸€è‡´

```
src/
â”œâ”€â”€ api/                          # ç½‘å…³å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ health.py
â”‚   â”‚   â”œâ”€â”€ index.py
â”‚   â”‚   â”œâ”€â”€ search.py
â”‚   â”‚   â””â”€â”€ tracks.py
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ requests.py
â”‚   â”‚   â””â”€â”€ responses.py
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ rate_limit.py
â”‚   â”‚   â””â”€â”€ tracing.py
â”‚   â””â”€â”€ dependencies.py
â”‚
â”œâ”€â”€ application/                  # åº”ç”¨å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ use_cases/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ index_video.py
â”‚   â”‚   â”œâ”€â”€ search_tracks.py
â”‚   â”‚   â”œâ”€â”€ generate_report.py
â”‚   â”‚   â””â”€â”€ realtime_index.py
â”‚   â””â”€â”€ dto/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ index_dto.py
â”‚       â””â”€â”€ search_dto.py
â”‚
â”œâ”€â”€ domain/                       # é¢†åŸŸå±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ video.py
â”‚   â”‚   â”œâ”€â”€ track.py
â”‚   â”‚   â””â”€â”€ evidence.py
â”‚   â”œâ”€â”€ value_objects/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bounding_box.py
â”‚   â”‚   â”œâ”€â”€ trajectory.py
â”‚   â”‚   â””â”€â”€ verification_result.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py
â”‚   â”‚   â”œâ”€â”€ motion_analyzer.py
â”‚   â”‚   â””â”€â”€ hard_rule_engine.py
â”‚   â””â”€â”€ events/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ domain_events.py
â”‚
â”œâ”€â”€ ports/                        # ç«¯å£å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference_port.py
â”‚   â”œâ”€â”€ storage_port.py
â”‚   â”œâ”€â”€ vector_store_port.py
â”‚   â””â”€â”€ message_queue_port.py
â”‚
â”œâ”€â”€ adapters/                     # é€‚é…å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vllm_adapter.py
â”‚   â”‚   â”œâ”€â”€ llamacpp_adapter.py
â”‚   â”‚   â”œâ”€â”€ model_registry.py
â”‚   â”‚   â””â”€â”€ response_parser.py
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ postgres_repo.py
â”‚   â”‚   â”œâ”€â”€ minio_adapter.py
â”‚   â”‚   â””â”€â”€ memory_repo.py
â”‚   â”œâ”€â”€ vector/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ qdrant_adapter.py
â”‚   â”œâ”€â”€ detection/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ yolo_adapter.py
â”‚   â”œâ”€â”€ streaming/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rtsp_processor.py
â”‚   â”‚   â””â”€â”€ camera_manager.py
â”‚   â”œâ”€â”€ reid/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ osnet_adapter.py
â”‚   â””â”€â”€ events/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ alert_system.py
â”‚
â”œâ”€â”€ infrastructure/               # åŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app_config.py
â”‚   â”‚   â””â”€â”€ infra_config.py
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ migrations/
â”‚   â””â”€â”€ logging/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ structured_logger.py
â”‚
â”œâ”€â”€ tasks/                        # å¼‚æ­¥ä»»åŠ¡
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ celery_app.py
â”‚   â””â”€â”€ indexing.py
â”‚
â””â”€â”€ tests/                        # æµ‹è¯•
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ unit/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

---

## å®Œæ•´åˆ é™¤æ¸…å•

> Phase 3 å®Œæˆåï¼Œåˆ é™¤æ‰€æœ‰æ—§ä»£ç 

### ğŸ”´ å¿…é¡»åˆ é™¤

| æ–‡ä»¶/ç›®å½• | ç†ç”± | æ›¿ä»£ |
|-----------|------|------|
| `src/pipeline/vlm_client_hf.py` | ç›´æ¥åŠ è½½æ¨¡å‹ï¼Œä¸ç¬¦åˆåˆ†å±‚æ¶æ„ | `adapters/inference/vllm_adapter.py` |
| `src/pipeline/vlm_client_vllm.py` (å¦‚æœæœ‰æ—§ç‰ˆ) | è¿ç§»åˆ° adapters | `adapters/inference/vllm_adapter.py` |
| `src/pipeline/recall.py` | è¿ç§»åˆ°åº”ç”¨å±‚ | `application/use_cases/search_tracks.py` |
| `src/pipeline/router.py` | è¿ç§»åˆ°åº”ç”¨å±‚ | `application/use_cases/` |
| `src/pipeline/router_llm.py` | åŒä¸Š | `application/use_cases/` |
| `src/core/config.py` | è¿ç§»åˆ° infrastructure | `infrastructure/config/` |
| `src/core/perception.py` | è¿ç§»åˆ° adapters | `adapters/detection/yolo_adapter.py` |
| `src/core/features.py` | è¿ç§»åˆ° domain | `domain/services/feature_extractor.py` |
| `src/core/evidence.py` | è¿ç§»åˆ° domain | `domain/entities/evidence.py` |
| `src/core/hard_rules.py` | è¿ç§»åˆ° domain | `domain/services/hard_rule_engine.py` |
| `src/core/vlm_types.py` | è¿ç§»åˆ° domain | `domain/value_objects/` |

### ğŸŸ¡ å¯é€‰åˆ é™¤

| æ–‡ä»¶/ç›®å½• | ç†ç”± | å»ºè®® |
|-----------|------|------|
| `src/pipeline/video_semantic_search.py` | æ—§å…¥å£ | ä¿ç•™ä½œä¸ºå‚è€ƒï¼Œååˆ é™¤ |
| `src/examples/` | æ—§ç¤ºä¾‹ä»£ç  | æ›´æ–°æˆ–åˆ é™¤ |

### æœ€ç»ˆåˆ é™¤å‘½ä»¤

```bash
# Phase 3 å®Œæˆåæ‰§è¡Œ
rm -rf src/pipeline/
rm -rf src/core/
rm -rf src/examples/

# ç¡®ä¿æ–°ç›®å½•å·²åˆ›å»º
ls -la src/api/
ls -la src/application/
ls -la src/domain/
ls -la src/ports/
ls -la src/adapters/
ls -la src/infrastructure/
ls -la src/tasks/
```

---

## éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- [ ] RTSP å®æ—¶æµå¤„ç†æ­£å¸¸
- [ ] å¤šæ‘„åƒå¤´ç®¡ç† API å¯ç”¨
- [ ] Re-ID è·¨é•œåŒ¹é…å¯ç”¨
- [ ] äº‹ä»¶å‘Šè­¦è§¦å‘æ­£å¸¸
- [ ] Webhook é€šçŸ¥å¯è¾¾

### æ€§èƒ½éªŒæ”¶

- [ ] å®æ—¶å»¶è¿Ÿ < 5s
- [ ] æ”¯æŒ 10+ æ‘„åƒå¤´å¹¶å‘
- [ ] API P99 å»¶è¿Ÿ < 500ms
- [ ] ç³»ç»Ÿ CPU < 80%

### éƒ¨ç½²éªŒæ”¶

- [ ] K8s éƒ¨ç½²æˆåŠŸ
- [ ] HPA è‡ªåŠ¨æ‰©ç¼©å®¹æ­£å¸¸
- [ ] å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] ç›‘æ§æŒ‡æ ‡å¯é‡‡é›†
- [ ] æ—¥å¿—å¯æ£€ç´¢

---

## é¡¹ç›®å®Œæˆæ ‡å¿—

å½“ä»¥ä¸‹æ¡ä»¶å…¨éƒ¨æ»¡è¶³æ—¶ï¼Œé¡¹ç›®é‡æ„å®Œæˆï¼š

1. âœ… ç›®å½•ç»“æ„ä¸ `final_upgrade_blueprint.md` ä¸€è‡´
2. âœ… æ‰€æœ‰æ—§ä»£ç å·²åˆ é™¤
3. âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡
4. âœ… æ–‡æ¡£æ›´æ–°å®Œæˆ
5. âœ… K8s éƒ¨ç½²æˆåŠŸ
6. âœ… ç›‘æ§å‘Šè­¦æ­£å¸¸

---

**æ­å–œï¼Edge-Detective å·¥ä¸šåŒ–å‡çº§å®Œæˆï¼** ğŸ‰

